
==============NVSMI LOG==============

Timestamp                                 : Sun Jun 11 16:59:19 2023
Driver Version                            : 515.105.01
CUDA Version                              : 11.7

Attached GPUs                             : 1
GPU 00000000:07:00.0
    Product Name                          : NVIDIA GeForce GTX TITAN X
    Product Brand                         : GeForce
    Product Architecture                  : Maxwell
    Display Mode                          : Disabled
    Display Active                        : Disabled
    Persistence Mode                      : Disabled
    MIG Mode
        Current                           : N/A
        Pending                           : N/A
    Accounting Mode                       : Disabled
    Accounting Mode Buffer Size           : 4000
    Driver Model
        Current                           : N/A
        Pending                           : N/A
    Serial Number                         : 0421116007421
    GPU UUID                              : GPU-c7667834-4fff-3dfc-8ece-4592e3280b68
    Minor Number                          : 1
    VBIOS Version                         : 84.00.45.00.03
    MultiGPU Board                        : No
    Board ID                              : 0x700
    GPU Part Number                       : N/A
    Module ID                             : 0
    Inforom Version
        Image Version                     : G001.0000.01.03
        OEM Object                        : 1.1
        ECC Object                        : N/A
        Power Management Object           : N/A
    GPU Operation Mode
        Current                           : N/A
        Pending                           : N/A
    GSP Firmware Version                  : N/A
    GPU Virtualization Mode
        Virtualization Mode               : None
        Host VGPU Mode                    : N/A
    IBMNPU
        Relaxed Ordering Mode             : N/A
    PCI
        Bus                               : 0x07
        Device                            : 0x00
        Domain                            : 0x0000
        Device Id                         : 0x17C210DE
        Bus Id                            : 00000000:07:00.0
        Sub System Id                     : 0x113210DE
        GPU Link Info
            PCIe Generation
                Max                       : 3
                Current                   : 1
            Link Width
                Max                       : 16x
                Current                   : 16x
        Bridge Chip
            Type                          : N/A
            Firmware                      : N/A
        Replays Since Reset               : 0
        Replay Number Rollovers           : 0
        Tx Throughput                     : 0 KB/s
        Rx Throughput                     : 0 KB/s
    Fan Speed                             : 22 %
    Performance State                     : P8
    Clocks Throttle Reasons
        Idle                              : Active
        Applications Clocks Setting       : Not Active
        SW Power Cap                      : Not Active
        HW Slowdown                       : Not Active
            HW Thermal Slowdown           : N/A
            HW Power Brake Slowdown       : N/A
        Sync Boost                        : Not Active
        SW Thermal Slowdown               : Not Active
        Display Clock Setting             : Not Active
    FB Memory Usage
        Total                             : 12288 MiB
        Reserved                          : 75 MiB
        Used                              : 0 MiB
        Free                              : 12212 MiB
    BAR1 Memory Usage
        Total                             : 256 MiB
        Used                              : 2 MiB
        Free                              : 254 MiB
    Compute Mode                          : Default
    Utilization
        Gpu                               : 0 %
        Memory                            : 0 %
        Encoder                           : 0 %
        Decoder                           : 0 %
    Encoder Stats
        Active Sessions                   : 0
        Average FPS                       : 0
        Average Latency                   : 0
    FBC Stats
        Active Sessions                   : 0
        Average FPS                       : 0
        Average Latency                   : 0
    Ecc Mode
        Current                           : N/A
        Pending                           : N/A
    ECC Errors
        Volatile
            Single Bit            
                Device Memory             : N/A
                Register File             : N/A
                L1 Cache                  : N/A
                L2 Cache                  : N/A
                Texture Memory            : N/A
                Texture Shared            : N/A
                CBU                       : N/A
                Total                     : N/A
            Double Bit            
                Device Memory             : N/A
                Register File             : N/A
                L1 Cache                  : N/A
                L2 Cache                  : N/A
                Texture Memory            : N/A
                Texture Shared            : N/A
                CBU                       : N/A
                Total                     : N/A
        Aggregate
            Single Bit            
                Device Memory             : N/A
                Register File             : N/A
                L1 Cache                  : N/A
                L2 Cache                  : N/A
                Texture Memory            : N/A
                Texture Shared            : N/A
                CBU                       : N/A
                Total                     : N/A
            Double Bit            
                Device Memory             : N/A
                Register File             : N/A
                L1 Cache                  : N/A
                L2 Cache                  : N/A
                Texture Memory            : N/A
                Texture Shared            : N/A
                CBU                       : N/A
                Total                     : N/A
    Retired Pages
        Single Bit ECC                    : N/A
        Double Bit ECC                    : N/A
        Pending Page Blacklist            : N/A
    Remapped Rows                         : N/A
    Temperature
        GPU Current Temp                  : 25 C
        GPU Shutdown Temp                 : 97 C
        GPU Slowdown Temp                 : 92 C
        GPU Max Operating Temp            : N/A
        GPU Target Temperature            : 83 C
        Memory Current Temp               : N/A
        Memory Max Operating Temp         : N/A
    Power Readings
        Power Management                  : Supported
        Power Draw                        : 15.94 W
        Power Limit                       : 250.00 W
        Default Power Limit               : 250.00 W
        Enforced Power Limit              : 250.00 W
        Min Power Limit                   : 150.00 W
        Max Power Limit                   : 275.00 W
    Clocks
        Graphics                          : 135 MHz
        SM                                : 135 MHz
        Memory                            : 405 MHz
        Video                             : 405 MHz
    Applications Clocks
        Graphics                          : 1000 MHz
        Memory                            : 3505 MHz
    Default Applications Clocks
        Graphics                          : 1000 MHz
        Memory                            : 3505 MHz
    Max Clocks
        Graphics                          : 1392 MHz
        SM                                : 1392 MHz
        Memory                            : 3505 MHz
        Video                             : 1281 MHz
    Max Customer Boost Clocks
        Graphics                          : N/A
    Clock Policy
        Auto Boost                        : On
        Auto Boost Default                : On
    Voltage
        Graphics                          : N/A
    Processes                             : None

wandb: Tracking run with wandb version 0.15.3
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
06/11/2023 17:01:29 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
06/11/2023 17:01:33 - INFO - __main__ -   Training/evaluation parameters {'train_data_file': '/disk/scratch_big/s2334723/dataset/train.jsonl', 'output_dir': '/disk/scratch_big/s2334723/saved_models/python_8', 'eval_data_file': '/disk/scratch_big/s2334723/dataset/valid.jsonl', 'test_data_file': '/disk/scratch_big/s2334723/dataset/test.jsonl', 'model_type': 'roberta', 'model_name_or_path': '/disk/scratch_big/s2334723/microsoft/codebert-base', 'mlm': False, 'mlm_probability': 0.15, 'config_name': '/disk/scratch_big/s2334723/microsoft/codebert-base', 'tokenizer_name': '/disk/scratch_big/s2334723/microsoft/codebert-base', 'cache_dir': '', 'block_size': 256, 'do_train': True, 'do_eval': False, 'do_test': False, 'evaluate_during_training': True, 'do_lower_case': False, 'train_batch_size': 8, 'eval_batch_size': 64, 'gradient_accumulation_steps': 1, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 2, 'save_total_limit': None, 'eval_all_checkpoints': False, 'no_cuda': False, 'overwrite_output_dir': False, 'overwrite_cache': False, 'seed': 123456, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'server_ip': '', 'server_port': '', 'gradient_checkpointing': False, 'gpu_batch_contrasting': False, 'n_gpu': 1, 'device': 'cuda', 'per_gpu_train_batch_size': 8, 'per_gpu_eval_batch_size': 64, 'start_epoch': 0, 'start_step': 0}
06/11/2023 17:08:42 - INFO - __main__ -   *** Example ***
06/11/2023 17:08:42 - INFO - __main__ -   idx: 0
06/11/2023 17:08:42 - INFO - __main__ -   code_tokens: ['<s>', 'def', '_split', '_', 'ph', 'yl', 'ogen', 'y', '_(', '_p', '_,', '_level', '_=', '_"', 's', '"', '_)', '_:', '_level', '_=', '_level', '_+', '_"', '__', '"', '_result', '_=', '_p', '_.', '_split', '_(', '_level', '_)', '_return', '_result', '_[', '_0', '_]', '_+', '_level', '_+', '_result', '_[', '_1', '_]', '_.', '_split', '_(', '_"', ';"', '_)', '_[', '_0', '_]', '</s>']
06/11/2023 17:08:42 - INFO - __main__ -   code_ids: 0 9232 3462 1215 3792 4360 11575 219 36 181 2156 672 5457 22 29 113 4839 4832 672 5457 672 2055 22 30529 113 898 5457 181 479 3462 36 672 4839 671 898 646 321 27779 2055 672 2055 898 646 112 27779 479 3462 36 22 42777 4839 646 321 27779 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
06/11/2023 17:08:42 - INFO - __main__ -   nl_tokens: ['<s>', 'Return', '_either', '_the', '_full', '_or', '_trunc', 'ated', '_version', '_of', '_a', '_Q', 'I', 'IME', '_-', '_formatted', '_tax', 'onomy', '_string', '_.', '</s>']
06/11/2023 17:08:42 - INFO - __main__ -   nl_ids: 0 42555 1169 5 455 50 43064 1070 1732 9 10 1209 100 28417 111 46625 629 38217 6755 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
06/11/2023 17:08:42 - INFO - __main__ -   *** Example ***
06/11/2023 17:08:42 - INFO - __main__ -   idx: 1
06/11/2023 17:08:42 - INFO - __main__ -   code_tokens: ['<s>', 'def', '_ensure', '_', 'dir', '_(', '_d', '_)', '_:', '_if', '_not', '_os', '_.', '_path', '_.', '_exists', '_(', '_d', '_)', '_:', '_try', '_:', '_os', '_.', '_m', 'aked', 'irs', '_(', '_d', '_)', '_except', '_O', 'SE', 'r', 'ror', '_as', '_o', 'e', '_:', '_#', '_should', '_not', '_happen', '_with', '_os', '.', 'm', 'aked', 'irs', '_#', '_EN', 'O', 'ENT', ':', '_No', '_such', '_file', '_or', '_directory', '_if', '_os', '_.', '_err', 'no', '_==', '_err', 'no', '_.', '_EN', 'O', 'ENT', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_"""', 'One', '_or', '_more', '_directories', '_in', '_the', '_path', '_({', '})', '_do', '_not', '_exist', '.', '_If', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_you', '_are', '_specifying', '_a', '_new', '_directory', '_for', '_output', ',', '_please', '_ensure', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_all', '_other', '_directories', '_in', '_the', '_path', '_currently', '_exist', '."', '""', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_)', '_else', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_"""', 'An', '_error', '_occurred', '_trying', '_to', '_create', '_the', '_output', '_directory', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_({', '})', '_with', '_message', ':', '_{}', '"""', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_,', '_o', 'e', '_.', '_stre', 'r', 'ror', '_)', '</s>']
06/11/2023 17:08:42 - INFO - __main__ -   code_ids: 0 9232 1306 1215 41292 36 385 4839 4832 114 45 11988 479 2718 479 8785 36 385 4839 4832 860 4832 11988 479 475 8435 21098 36 385 4839 4682 384 3388 338 21929 25 1021 242 4832 849 197 45 1369 19 11988 4 119 8435 21098 849 13245 673 5382 35 440 215 2870 50 31826 114 11988 479 22379 2362 45994 22379 2362 479 13245 673 5382 4832 49049 5457 11901 16134 36 49434 3762 50 55 44472 11 5 2718 49698 49424 109 45 5152 4 318 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 47 32 39140 10 92 31826 13 4195 6 2540 1306 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 70 97 44472 11 5 2718 855 5152 72 48149 4839 671 49049 479 7390 36 385 4839 1493 4832 49049 5457 11901 16134 36 49434 4688 5849 2756 667 7 1045 5 4195 31826 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 49698 49424 19 1579 35 49153 49849 4839 671 49049 479 7390 36 385 2156 1021 242 479 22246 338 21929 4839 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
06/11/2023 17:08:42 - INFO - __main__ -   nl_tokens: ['<s>', 'Check', '_to', '_make', '_sure', '_the', '_supplied', '_directory', '_path', '_does', '_not', '_exist', '_if', '_so', '_create', '_it', '_.', '_The', '_method', '_catches', '_O', 'SE', 'r', 'ror', '_exceptions', '_and', '_returns', '_a', '_descriptive', '_message', '_instead', '_of', '_re', '_-', '_raising', '_the', '_error', '_.', '</s>']
06/11/2023 17:08:42 - INFO - __main__ -   nl_ids: 0 26615 7 146 686 5 12359 31826 2718 473 45 5152 114 98 1045 24 479 20 5448 8758 384 3388 338 21929 18286 8 2886 10 42690 1579 1386 9 769 111 3282 5 5849 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
06/11/2023 17:08:42 - INFO - __main__ -   *** Example ***
06/11/2023 17:08:42 - INFO - __main__ -   idx: 2
06/11/2023 17:08:42 - INFO - __main__ -   code_tokens: ['<s>', 'def', '_file', '_', 'handle', '_(', '_fn', 'h', '_,', '_mode', '_=', '_"', 'r', 'U', '"', '_)', '_:', '_handle', '_=', '_None', '_if', '_is', 'instance', '_(', '_fn', 'h', '_,', '_file', '_)', '_:', '_if', '_fn', 'h', '_.', '_closed', '_:', '_raise', '_Value', 'Error', '_(', '_"', 'Input', '_file', '_is', '_closed', '."', '_)', '_handle', '_=', '_fn', 'h', '_el', 'if', '_is', 'instance', '_(', '_fn', 'h', '_,', '_str', '_)', '_:', '_handle', '_=', '_open', '_(', '_fn', 'h', '_,', '_mode', '_)', '_return', '_handle', '</s>']
06/11/2023 17:08:42 - INFO - __main__ -   code_ids: 0 9232 2870 1215 26628 36 48930 298 2156 5745 5457 22 338 791 113 4839 4832 3679 5457 9291 114 16 48768 36 48930 298 2156 2870 4839 4832 114 48930 298 479 1367 4832 1693 11714 30192 36 22 48214 2870 16 1367 72 4839 3679 5457 48930 298 1615 1594 16 48768 36 48930 298 2156 7031 4839 4832 3679 5457 490 36 48930 298 2156 5745 4839 671 3679 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
06/11/2023 17:08:42 - INFO - __main__ -   nl_tokens: ['<s>', 'T', 'akes', '_either', '_a', '_file', '_path', '_or', '_an', '_open', '_file', '_handle', '_checks', '_validity', '_and', '_returns', '_an', '_open', '_file', '_handle', '_or', '_raises', '_an', '_appropriate', '_Exception', '_.', '</s>']
06/11/2023 17:08:42 - INFO - __main__ -   nl_ids: 0 565 5556 1169 10 2870 2718 50 41 490 2870 3679 6240 25295 8 2886 41 490 2870 3679 50 7700 41 3901 47617 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
/home/s2334723/micromamba/envs/ML3.8/lib/python3.8/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
06/11/2023 17:08:53 - INFO - __main__ -   ***** Running training *****
06/11/2023 17:08:53 - INFO - __main__ -     Num examples = 251820
06/11/2023 17:08:53 - INFO - __main__ -     Num Epochs = 2
06/11/2023 17:08:53 - INFO - __main__ -     Instantaneous batch size per GPU = 8
06/11/2023 17:08:53 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 8
06/11/2023 17:08:53 - INFO - __main__ -     Gradient Accumulation steps = 1
06/11/2023 17:08:53 - INFO - __main__ -     Total optimization steps = 62956
06/11/2023 17:10:01 - INFO - __main__ -   epoch 0 step 100 loss 11.04305
06/11/2023 17:11:05 - INFO - __main__ -   epoch 0 step 200 loss 9.02361
06/11/2023 17:12:08 - INFO - __main__ -   epoch 0 step 300 loss 7.43529
06/11/2023 17:13:12 - INFO - __main__ -   epoch 0 step 400 loss 6.22754
06/11/2023 17:14:16 - INFO - __main__ -   epoch 0 step 500 loss 5.25977
06/11/2023 17:15:19 - INFO - __main__ -   epoch 0 step 600 loss 4.49186
06/11/2023 17:16:23 - INFO - __main__ -   epoch 0 step 700 loss 3.90656
06/11/2023 17:17:26 - INFO - __main__ -   epoch 0 step 800 loss 3.45149
06/11/2023 17:18:30 - INFO - __main__ -   epoch 0 step 900 loss 3.08903
06/11/2023 17:19:34 - INFO - __main__ -   epoch 0 step 1000 loss 2.80947
06/11/2023 17:20:37 - INFO - __main__ -   epoch 0 step 1100 loss 2.57583
06/11/2023 17:21:41 - INFO - __main__ -   epoch 0 step 1200 loss 2.37201
06/11/2023 17:22:44 - INFO - __main__ -   epoch 0 step 1300 loss 2.20525
06/11/2023 17:23:48 - INFO - __main__ -   epoch 0 step 1400 loss 2.05838
06/11/2023 17:24:52 - INFO - __main__ -   epoch 0 step 1500 loss 1.92893
06/11/2023 17:25:55 - INFO - __main__ -   epoch 0 step 1600 loss 1.81778
06/11/2023 17:26:59 - INFO - __main__ -   epoch 0 step 1700 loss 1.71977
06/11/2023 17:28:02 - INFO - __main__ -   epoch 0 step 1800 loss 1.63081
06/11/2023 17:29:06 - INFO - __main__ -   epoch 0 step 1900 loss 1.55147
06/11/2023 17:30:10 - INFO - __main__ -   epoch 0 step 2000 loss 1.48233
06/11/2023 17:31:13 - INFO - __main__ -   epoch 0 step 2100 loss 1.41927
06/11/2023 17:32:17 - INFO - __main__ -   epoch 0 step 2200 loss 1.36173
06/11/2023 17:33:20 - INFO - __main__ -   epoch 0 step 2300 loss 1.3084
06/11/2023 17:34:24 - INFO - __main__ -   epoch 0 step 2400 loss 1.25843
06/11/2023 17:35:28 - INFO - __main__ -   epoch 0 step 2500 loss 1.21432
06/11/2023 17:36:31 - INFO - __main__ -   epoch 0 step 2600 loss 1.17155
06/11/2023 17:37:35 - INFO - __main__ -   epoch 0 step 2700 loss 1.13248
06/11/2023 17:38:38 - INFO - __main__ -   epoch 0 step 2800 loss 1.09761
06/11/2023 17:39:42 - INFO - __main__ -   epoch 0 step 2900 loss 1.06466
06/11/2023 17:40:46 - INFO - __main__ -   epoch 0 step 3000 loss 1.03532
06/11/2023 17:41:49 - INFO - __main__ -   epoch 0 step 3100 loss 1.00592
06/11/2023 17:42:35 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 17:42:35 - INFO - __main__ -     Num examples = 9604
06/11/2023 17:42:35 - INFO - __main__ -     Batch size = 64
06/11/2023 17:47:58 - INFO - __main__ -     eval_loss = 2.5198
06/11/2023 17:47:58 - INFO - __main__ -     eval_mrr = 0.2353
06/11/2023 17:47:58 - INFO - __main__ -     ********************
06/11/2023 17:47:58 - INFO - __main__ -     Best mrr:0.2353
06/11/2023 17:47:58 - INFO - __main__ -     ********************
06/11/2023 17:47:59 - INFO - __main__ -   Saving model checkpoint to /disk/scratch_big/s2334723/saved_models/python_8/checkpoint-best-mrr/model.bin
06/11/2023 17:48:33 - INFO - __main__ -   epoch 0 step 3200 loss 0.12007
06/11/2023 17:49:37 - INFO - __main__ -   epoch 0 step 3300 loss 0.17306
06/11/2023 17:50:42 - INFO - __main__ -   epoch 0 step 3400 loss 0.17998
06/11/2023 17:51:46 - INFO - __main__ -   epoch 0 step 3500 loss 0.15886
06/11/2023 17:52:49 - INFO - __main__ -   epoch 0 step 3600 loss 0.16691
06/11/2023 17:53:53 - INFO - __main__ -   epoch 0 step 3700 loss 0.16931
06/11/2023 17:54:57 - INFO - __main__ -   epoch 0 step 3800 loss 0.15969
06/11/2023 17:56:00 - INFO - __main__ -   epoch 0 step 3900 loss 0.171
06/11/2023 17:57:04 - INFO - __main__ -   epoch 0 step 4000 loss 0.16337
06/11/2023 17:58:08 - INFO - __main__ -   epoch 0 step 4100 loss 0.16426
06/11/2023 17:59:11 - INFO - __main__ -   epoch 0 step 4200 loss 0.16677
06/11/2023 18:00:15 - INFO - __main__ -   epoch 0 step 4300 loss 0.17498
06/11/2023 18:01:19 - INFO - __main__ -   epoch 0 step 4400 loss 0.17942
06/11/2023 18:02:23 - INFO - __main__ -   epoch 0 step 4500 loss 0.18809
06/11/2023 18:03:26 - INFO - __main__ -   epoch 0 step 4600 loss 0.18945
06/11/2023 18:04:30 - INFO - __main__ -   epoch 0 step 4700 loss 0.18207
06/11/2023 18:05:34 - INFO - __main__ -   epoch 0 step 4800 loss 0.18733
06/11/2023 18:06:37 - INFO - __main__ -   epoch 0 step 4900 loss 0.18727
06/11/2023 18:07:41 - INFO - __main__ -   epoch 0 step 5000 loss 0.18608
06/11/2023 18:08:45 - INFO - __main__ -   epoch 0 step 5100 loss 0.18405
06/11/2023 18:09:48 - INFO - __main__ -   epoch 0 step 5200 loss 0.18499
06/11/2023 18:10:52 - INFO - __main__ -   epoch 0 step 5300 loss 0.18714
06/11/2023 18:11:56 - INFO - __main__ -   epoch 0 step 5400 loss 0.19004
06/11/2023 18:12:59 - INFO - __main__ -   epoch 0 step 5500 loss 0.19045
06/11/2023 18:14:03 - INFO - __main__ -   epoch 0 step 5600 loss 0.19572
06/11/2023 18:15:07 - INFO - __main__ -   epoch 0 step 5700 loss 0.19663
06/11/2023 18:16:11 - INFO - __main__ -   epoch 0 step 5800 loss 0.19862
06/11/2023 18:17:14 - INFO - __main__ -   epoch 0 step 5900 loss 0.1983
06/11/2023 18:18:18 - INFO - __main__ -   epoch 0 step 6000 loss 0.19759
06/11/2023 18:19:22 - INFO - __main__ -   epoch 0 step 6100 loss 0.20181
06/11/2023 18:20:25 - INFO - __main__ -   epoch 0 step 6200 loss 0.20411
06/11/2023 18:21:25 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 18:21:25 - INFO - __main__ -     Num examples = 9604
06/11/2023 18:21:25 - INFO - __main__ -     Batch size = 64
06/11/2023 18:26:47 - INFO - __main__ -     eval_loss = 4.1375
06/11/2023 18:26:47 - INFO - __main__ -     eval_mrr = 0.1866
06/11/2023 18:26:51 - INFO - __main__ -   epoch 0 step 6300 loss 0.53113
06/11/2023 18:27:55 - INFO - __main__ -   epoch 0 step 6400 loss 0.20439
06/11/2023 18:29:01 - INFO - __main__ -   epoch 0 step 6500 loss 0.24869
06/11/2023 18:30:05 - INFO - __main__ -   epoch 0 step 6600 loss 0.26997
06/11/2023 18:31:09 - INFO - __main__ -   epoch 0 step 6700 loss 0.26973
06/11/2023 18:32:13 - INFO - __main__ -   epoch 0 step 6800 loss 0.24262
06/11/2023 18:33:17 - INFO - __main__ -   epoch 0 step 6900 loss 0.24466
06/11/2023 18:34:21 - INFO - __main__ -   epoch 0 step 7000 loss 0.25328
06/11/2023 18:35:25 - INFO - __main__ -   epoch 0 step 7100 loss 0.24549
06/11/2023 18:36:29 - INFO - __main__ -   epoch 0 step 7200 loss 0.25474
06/11/2023 18:37:33 - INFO - __main__ -   epoch 0 step 7300 loss 0.25302
06/11/2023 18:38:36 - INFO - __main__ -   epoch 0 step 7400 loss 0.25353
06/11/2023 18:39:40 - INFO - __main__ -   epoch 0 step 7500 loss 0.25502
06/11/2023 18:40:44 - INFO - __main__ -   epoch 0 step 7600 loss 0.25473
06/11/2023 18:41:48 - INFO - __main__ -   epoch 0 step 7700 loss 0.26306
06/11/2023 18:42:52 - INFO - __main__ -   epoch 0 step 7800 loss 0.26462
06/11/2023 18:43:55 - INFO - __main__ -   epoch 0 step 7900 loss 0.2615
06/11/2023 18:44:59 - INFO - __main__ -   epoch 0 step 8000 loss 0.25886
06/11/2023 18:46:03 - INFO - __main__ -   epoch 0 step 8100 loss 0.25949
06/11/2023 18:47:06 - INFO - __main__ -   epoch 0 step 8200 loss 0.26563
06/11/2023 18:48:10 - INFO - __main__ -   epoch 0 step 8300 loss 0.26419
06/11/2023 18:49:14 - INFO - __main__ -   epoch 0 step 8400 loss 0.26473
06/11/2023 18:50:18 - INFO - __main__ -   epoch 0 step 8500 loss 0.26276
06/11/2023 18:51:21 - INFO - __main__ -   epoch 0 step 8600 loss 0.26454
06/11/2023 18:52:25 - INFO - __main__ -   epoch 0 step 8700 loss 0.26363
06/11/2023 18:53:29 - INFO - __main__ -   epoch 0 step 8800 loss 0.26122
06/11/2023 18:54:32 - INFO - __main__ -   epoch 0 step 8900 loss 0.26405
06/11/2023 18:55:36 - INFO - __main__ -   epoch 0 step 9000 loss 0.26199
06/11/2023 18:56:40 - INFO - __main__ -   epoch 0 step 9100 loss 0.26367
06/11/2023 18:57:44 - INFO - __main__ -   epoch 0 step 9200 loss 0.26247
06/11/2023 18:58:47 - INFO - __main__ -   epoch 0 step 9300 loss 0.26398
06/11/2023 18:59:51 - INFO - __main__ -   epoch 0 step 9400 loss 0.26461
06/11/2023 19:00:17 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 19:00:17 - INFO - __main__ -     Num examples = 9604
06/11/2023 19:00:17 - INFO - __main__ -     Batch size = 64
06/11/2023 19:05:35 - INFO - __main__ -     eval_loss = 4.3007
06/11/2023 19:05:35 - INFO - __main__ -     eval_mrr = 0.1497
06/11/2023 19:06:12 - INFO - __main__ -   epoch 0 step 9500 loss 0.47233
06/11/2023 19:07:17 - INFO - __main__ -   epoch 0 step 9600 loss 0.32913
06/11/2023 19:08:22 - INFO - __main__ -   epoch 0 step 9700 loss 0.32905
06/11/2023 19:09:26 - INFO - __main__ -   epoch 0 step 9800 loss 0.30671
06/11/2023 19:10:30 - INFO - __main__ -   epoch 0 step 9900 loss 0.29997
06/11/2023 19:11:34 - INFO - __main__ -   epoch 0 step 10000 loss 0.30594
06/11/2023 19:12:37 - INFO - __main__ -   epoch 0 step 10100 loss 0.29944
06/11/2023 19:13:41 - INFO - __main__ -   epoch 0 step 10200 loss 0.2852
06/11/2023 19:14:45 - INFO - __main__ -   epoch 0 step 10300 loss 0.28296
06/11/2023 19:15:48 - INFO - __main__ -   epoch 0 step 10400 loss 0.28478
06/11/2023 19:16:52 - INFO - __main__ -   epoch 0 step 10500 loss 0.29044
06/11/2023 19:17:56 - INFO - __main__ -   epoch 0 step 10600 loss 0.29197
06/11/2023 19:18:59 - INFO - __main__ -   epoch 0 step 10700 loss 0.28982
06/11/2023 19:20:03 - INFO - __main__ -   epoch 0 step 10800 loss 0.29089
06/11/2023 19:21:07 - INFO - __main__ -   epoch 0 step 10900 loss 0.28837
06/11/2023 19:22:10 - INFO - __main__ -   epoch 0 step 11000 loss 0.28737
06/11/2023 19:23:14 - INFO - __main__ -   epoch 0 step 11100 loss 0.28953
06/11/2023 19:24:18 - INFO - __main__ -   epoch 0 step 11200 loss 0.28611
06/11/2023 19:25:21 - INFO - __main__ -   epoch 0 step 11300 loss 0.2812
06/11/2023 19:26:25 - INFO - __main__ -   epoch 0 step 11400 loss 0.27774
06/11/2023 19:27:29 - INFO - __main__ -   epoch 0 step 11500 loss 0.27559
06/11/2023 19:28:32 - INFO - __main__ -   epoch 0 step 11600 loss 0.27332
06/11/2023 19:29:36 - INFO - __main__ -   epoch 0 step 11700 loss 0.26969
06/11/2023 19:30:40 - INFO - __main__ -   epoch 0 step 11800 loss 0.2705
06/11/2023 19:31:43 - INFO - __main__ -   epoch 0 step 11900 loss 0.27145
06/11/2023 19:32:47 - INFO - __main__ -   epoch 0 step 12000 loss 0.26953
06/11/2023 19:33:51 - INFO - __main__ -   epoch 0 step 12100 loss 0.26508
06/11/2023 19:34:54 - INFO - __main__ -   epoch 0 step 12200 loss 0.26635
06/11/2023 19:35:58 - INFO - __main__ -   epoch 0 step 12300 loss 0.26585
06/11/2023 19:37:02 - INFO - __main__ -   epoch 0 step 12400 loss 0.26897
06/11/2023 19:38:05 - INFO - __main__ -   epoch 0 step 12500 loss 0.2661
06/11/2023 19:39:01 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 19:39:01 - INFO - __main__ -     Num examples = 9604
06/11/2023 19:39:01 - INFO - __main__ -     Batch size = 64
06/11/2023 19:44:26 - INFO - __main__ -     eval_loss = 4.4083
06/11/2023 19:44:26 - INFO - __main__ -     eval_mrr = 0.1276
06/11/2023 19:44:33 - INFO - __main__ -   epoch 0 step 12600 loss 0.53181
06/11/2023 19:45:37 - INFO - __main__ -   epoch 0 step 12700 loss 0.33115
06/11/2023 19:46:42 - INFO - __main__ -   epoch 0 step 12800 loss 0.3444
06/11/2023 19:47:46 - INFO - __main__ -   epoch 0 step 12900 loss 0.3047
06/11/2023 19:48:50 - INFO - __main__ -   epoch 0 step 13000 loss 0.2882
06/11/2023 19:49:53 - INFO - __main__ -   epoch 0 step 13100 loss 0.28435
06/11/2023 19:50:57 - INFO - __main__ -   epoch 0 step 13200 loss 0.27089
06/11/2023 19:52:01 - INFO - __main__ -   epoch 0 step 13300 loss 0.25068
06/11/2023 19:53:04 - INFO - __main__ -   epoch 0 step 13400 loss 0.25413
06/11/2023 19:54:08 - INFO - __main__ -   epoch 0 step 13500 loss 0.24657
06/11/2023 19:55:12 - INFO - __main__ -   epoch 0 step 13600 loss 0.24834
06/11/2023 19:56:15 - INFO - __main__ -   epoch 0 step 13700 loss 0.25
06/11/2023 19:57:19 - INFO - __main__ -   epoch 0 step 13800 loss 0.25306
06/11/2023 19:58:23 - INFO - __main__ -   epoch 0 step 13900 loss 0.25844
06/11/2023 19:59:27 - INFO - __main__ -   epoch 0 step 14000 loss 0.26238
06/11/2023 20:00:30 - INFO - __main__ -   epoch 0 step 14100 loss 0.26024
06/11/2023 20:01:34 - INFO - __main__ -   epoch 0 step 14200 loss 0.25586
06/11/2023 20:02:38 - INFO - __main__ -   epoch 0 step 14300 loss 0.25162
06/11/2023 20:03:41 - INFO - __main__ -   epoch 0 step 14400 loss 0.25408
06/11/2023 20:04:45 - INFO - __main__ -   epoch 0 step 14500 loss 0.25292
06/11/2023 20:05:49 - INFO - __main__ -   epoch 0 step 14600 loss 0.25039
06/11/2023 20:06:52 - INFO - __main__ -   epoch 0 step 14700 loss 0.25399
06/11/2023 20:07:56 - INFO - __main__ -   epoch 0 step 14800 loss 0.25566
06/11/2023 20:09:00 - INFO - __main__ -   epoch 0 step 14900 loss 0.25683
06/11/2023 20:10:04 - INFO - __main__ -   epoch 0 step 15000 loss 0.25714
06/11/2023 20:11:07 - INFO - __main__ -   epoch 0 step 15100 loss 0.25707
06/11/2023 20:12:11 - INFO - __main__ -   epoch 0 step 15200 loss 0.2528
06/11/2023 20:13:15 - INFO - __main__ -   epoch 0 step 15300 loss 0.25528
06/11/2023 20:14:18 - INFO - __main__ -   epoch 0 step 15400 loss 0.25575
06/11/2023 20:15:22 - INFO - __main__ -   epoch 0 step 15500 loss 0.25765
06/11/2023 20:16:26 - INFO - __main__ -   epoch 0 step 15600 loss 0.25744
06/11/2023 20:17:29 - INFO - __main__ -   epoch 0 step 15700 loss 0.25786
06/11/2023 20:17:52 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 20:17:52 - INFO - __main__ -     Num examples = 9604
06/11/2023 20:17:52 - INFO - __main__ -     Batch size = 64
06/11/2023 20:23:14 - INFO - __main__ -     eval_loss = 2.7626
06/11/2023 20:23:14 - INFO - __main__ -     eval_mrr = 0.2018
06/11/2023 20:23:55 - INFO - __main__ -   epoch 0 step 15800 loss 0.24188
06/11/2023 20:25:00 - INFO - __main__ -   epoch 0 step 15900 loss 0.20322
06/11/2023 20:26:04 - INFO - __main__ -   epoch 0 step 16000 loss 0.22919
06/11/2023 20:27:08 - INFO - __main__ -   epoch 0 step 16100 loss 0.21547
06/11/2023 20:28:12 - INFO - __main__ -   epoch 0 step 16200 loss 0.20075
06/11/2023 20:29:15 - INFO - __main__ -   epoch 0 step 16300 loss 0.23062
06/11/2023 20:30:19 - INFO - __main__ -   epoch 0 step 16400 loss 0.23264
06/11/2023 20:31:23 - INFO - __main__ -   epoch 0 step 16500 loss 0.24616
06/11/2023 20:32:26 - INFO - __main__ -   epoch 0 step 16600 loss 0.24628
06/11/2023 20:33:30 - INFO - __main__ -   epoch 0 step 16700 loss 0.24241
06/11/2023 20:34:34 - INFO - __main__ -   epoch 0 step 16800 loss 0.23907
06/11/2023 20:35:37 - INFO - __main__ -   epoch 0 step 16900 loss 0.2349
06/11/2023 20:36:41 - INFO - __main__ -   epoch 0 step 17000 loss 0.23107
06/11/2023 20:37:45 - INFO - __main__ -   epoch 0 step 17100 loss 0.22904
06/11/2023 20:38:48 - INFO - __main__ -   epoch 0 step 17200 loss 0.22685
06/11/2023 20:39:52 - INFO - __main__ -   epoch 0 step 17300 loss 0.23233
06/11/2023 20:40:56 - INFO - __main__ -   epoch 0 step 17400 loss 0.24001
06/11/2023 20:41:59 - INFO - __main__ -   epoch 0 step 17500 loss 0.24027
06/11/2023 20:43:03 - INFO - __main__ -   epoch 0 step 17600 loss 0.23815
06/11/2023 20:44:07 - INFO - __main__ -   epoch 0 step 17700 loss 0.23632
06/11/2023 20:45:10 - INFO - __main__ -   epoch 0 step 17800 loss 0.23261
06/11/2023 20:46:14 - INFO - __main__ -   epoch 0 step 17900 loss 0.23185
06/11/2023 20:47:18 - INFO - __main__ -   epoch 0 step 18000 loss 0.23284
06/11/2023 20:48:21 - INFO - __main__ -   epoch 0 step 18100 loss 0.23351
06/11/2023 20:49:25 - INFO - __main__ -   epoch 0 step 18200 loss 0.23395
06/11/2023 20:50:29 - INFO - __main__ -   epoch 0 step 18300 loss 0.23299
06/11/2023 20:51:33 - INFO - __main__ -   epoch 0 step 18400 loss 0.23165
06/11/2023 20:52:36 - INFO - __main__ -   epoch 0 step 18500 loss 0.23155
06/11/2023 20:53:40 - INFO - __main__ -   epoch 0 step 18600 loss 0.23009
06/11/2023 20:54:44 - INFO - __main__ -   epoch 0 step 18700 loss 0.23182
06/11/2023 20:55:47 - INFO - __main__ -   epoch 0 step 18800 loss 0.22855
06/11/2023 20:56:40 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 20:56:40 - INFO - __main__ -     Num examples = 9604
06/11/2023 20:56:40 - INFO - __main__ -     Batch size = 64
06/11/2023 21:01:59 - INFO - __main__ -     eval_loss = 3.235
06/11/2023 21:01:59 - INFO - __main__ -     eval_mrr = 0.1327
06/11/2023 21:02:11 - INFO - __main__ -   epoch 0 step 18900 loss 0.21981
06/11/2023 21:03:15 - INFO - __main__ -   epoch 0 step 19000 loss 0.25126
06/11/2023 21:04:20 - INFO - __main__ -   epoch 0 step 19100 loss 0.31486
06/11/2023 21:05:24 - INFO - __main__ -   epoch 0 step 19200 loss 0.27761
06/11/2023 21:06:28 - INFO - __main__ -   epoch 0 step 19300 loss 0.25038
06/11/2023 21:07:32 - INFO - __main__ -   epoch 0 step 19400 loss 0.23042
06/11/2023 21:08:36 - INFO - __main__ -   epoch 0 step 19500 loss 0.22171
06/11/2023 21:09:40 - INFO - __main__ -   epoch 0 step 19600 loss 0.21775
06/11/2023 21:10:43 - INFO - __main__ -   epoch 0 step 19700 loss 0.21866
06/11/2023 21:11:47 - INFO - __main__ -   epoch 0 step 19800 loss 0.21992
06/11/2023 21:12:51 - INFO - __main__ -   epoch 0 step 19900 loss 0.22022
06/11/2023 21:13:55 - INFO - __main__ -   epoch 0 step 20000 loss 0.21729
06/11/2023 21:14:58 - INFO - __main__ -   epoch 0 step 20100 loss 0.21778
06/11/2023 21:16:02 - INFO - __main__ -   epoch 0 step 20200 loss 0.21195
06/11/2023 21:17:06 - INFO - __main__ -   epoch 0 step 20300 loss 0.21704
06/11/2023 21:18:09 - INFO - __main__ -   epoch 0 step 20400 loss 0.21732
06/11/2023 21:19:13 - INFO - __main__ -   epoch 0 step 20500 loss 0.21839
06/11/2023 21:20:17 - INFO - __main__ -   epoch 0 step 20600 loss 0.22146
06/11/2023 21:21:20 - INFO - __main__ -   epoch 0 step 20700 loss 0.22396
06/11/2023 21:22:24 - INFO - __main__ -   epoch 0 step 20800 loss 0.22117
06/11/2023 21:23:28 - INFO - __main__ -   epoch 0 step 20900 loss 0.22307
06/11/2023 21:24:32 - INFO - __main__ -   epoch 0 step 21000 loss 0.22313
06/11/2023 21:25:35 - INFO - __main__ -   epoch 0 step 21100 loss 0.2218
06/11/2023 21:26:39 - INFO - __main__ -   epoch 0 step 21200 loss 0.22276
06/11/2023 21:27:43 - INFO - __main__ -   epoch 0 step 21300 loss 0.22197
06/11/2023 21:28:46 - INFO - __main__ -   epoch 0 step 21400 loss 0.22027
06/11/2023 21:29:50 - INFO - __main__ -   epoch 0 step 21500 loss 0.21867
06/11/2023 21:30:54 - INFO - __main__ -   epoch 0 step 21600 loss 0.21742
06/11/2023 21:31:57 - INFO - __main__ -   epoch 0 step 21700 loss 0.21538
06/11/2023 21:33:01 - INFO - __main__ -   epoch 0 step 21800 loss 0.21486
06/11/2023 21:34:05 - INFO - __main__ -   epoch 0 step 21900 loss 0.21804
06/11/2023 21:35:08 - INFO - __main__ -   epoch 0 step 22000 loss 0.21548
06/11/2023 21:35:27 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 21:35:27 - INFO - __main__ -     Num examples = 9604
06/11/2023 21:35:27 - INFO - __main__ -     Batch size = 64
06/11/2023 21:40:56 - INFO - __main__ -     eval_loss = 3.3386
06/11/2023 21:40:56 - INFO - __main__ -     eval_mrr = 0.189
06/11/2023 21:41:41 - INFO - __main__ -   epoch 0 step 22100 loss 0.18287
06/11/2023 21:42:46 - INFO - __main__ -   epoch 0 step 22200 loss 0.16949
06/11/2023 21:43:50 - INFO - __main__ -   epoch 0 step 22300 loss 0.16029
06/11/2023 21:44:54 - INFO - __main__ -   epoch 0 step 22400 loss 0.15735
06/11/2023 21:45:58 - INFO - __main__ -   epoch 0 step 22500 loss 0.16435
06/11/2023 21:47:02 - INFO - __main__ -   epoch 0 step 22600 loss 0.16605
06/11/2023 21:48:05 - INFO - __main__ -   epoch 0 step 22700 loss 0.17791
06/11/2023 21:49:09 - INFO - __main__ -   epoch 0 step 22800 loss 0.19282
06/11/2023 21:50:13 - INFO - __main__ -   epoch 0 step 22900 loss 0.19995
06/11/2023 21:51:16 - INFO - __main__ -   epoch 0 step 23000 loss 0.19774
06/11/2023 21:52:20 - INFO - __main__ -   epoch 0 step 23100 loss 0.20164
06/11/2023 21:53:24 - INFO - __main__ -   epoch 0 step 23200 loss 0.20598
06/11/2023 21:54:28 - INFO - __main__ -   epoch 0 step 23300 loss 0.20959
06/11/2023 21:55:31 - INFO - __main__ -   epoch 0 step 23400 loss 0.20342
06/11/2023 21:56:35 - INFO - __main__ -   epoch 0 step 23500 loss 0.19771
06/11/2023 21:57:39 - INFO - __main__ -   epoch 0 step 23600 loss 0.19574
06/11/2023 21:58:42 - INFO - __main__ -   epoch 0 step 23700 loss 0.19651
06/11/2023 21:59:46 - INFO - __main__ -   epoch 0 step 23800 loss 0.19285
06/11/2023 22:00:50 - INFO - __main__ -   epoch 0 step 23900 loss 0.19549
06/11/2023 22:01:53 - INFO - __main__ -   epoch 0 step 24000 loss 0.19536
06/11/2023 22:02:57 - INFO - __main__ -   epoch 0 step 24100 loss 0.1921
06/11/2023 22:04:01 - INFO - __main__ -   epoch 0 step 24200 loss 0.19004
06/11/2023 22:05:05 - INFO - __main__ -   epoch 0 step 24300 loss 0.19099
06/11/2023 22:06:08 - INFO - __main__ -   epoch 0 step 24400 loss 0.19178
06/11/2023 22:07:12 - INFO - __main__ -   epoch 0 step 24500 loss 0.1893
06/11/2023 22:08:16 - INFO - __main__ -   epoch 0 step 24600 loss 0.19115
06/11/2023 22:09:19 - INFO - __main__ -   epoch 0 step 24700 loss 0.19274
06/11/2023 22:10:23 - INFO - __main__ -   epoch 0 step 24800 loss 0.19318
06/11/2023 22:11:27 - INFO - __main__ -   epoch 0 step 24900 loss 0.19252
06/11/2023 22:12:30 - INFO - __main__ -   epoch 0 step 25000 loss 0.19656
06/11/2023 22:13:34 - INFO - __main__ -   epoch 0 step 25100 loss 0.19795
06/11/2023 22:14:23 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 22:14:23 - INFO - __main__ -     Num examples = 9604
06/11/2023 22:14:23 - INFO - __main__ -     Batch size = 64
06/11/2023 22:19:49 - INFO - __main__ -     eval_loss = 3.0629
06/11/2023 22:19:49 - INFO - __main__ -     eval_mrr = 0.1812
06/11/2023 22:20:04 - INFO - __main__ -   epoch 0 step 25200 loss 0.13835
06/11/2023 22:21:08 - INFO - __main__ -   epoch 0 step 25300 loss 0.18841
06/11/2023 22:22:13 - INFO - __main__ -   epoch 0 step 25400 loss 0.22319
06/11/2023 22:23:17 - INFO - __main__ -   epoch 0 step 25500 loss 0.20175
06/11/2023 22:24:21 - INFO - __main__ -   epoch 0 step 25600 loss 0.20867
06/11/2023 22:25:25 - INFO - __main__ -   epoch 0 step 25700 loss 0.21015
06/11/2023 22:26:28 - INFO - __main__ -   epoch 0 step 25800 loss 0.20121
06/11/2023 22:27:32 - INFO - __main__ -   epoch 0 step 25900 loss 0.1937
06/11/2023 22:28:36 - INFO - __main__ -   epoch 0 step 26000 loss 0.1911
06/11/2023 22:29:39 - INFO - __main__ -   epoch 0 step 26100 loss 0.18551
06/11/2023 22:30:43 - INFO - __main__ -   epoch 0 step 26200 loss 0.17968
06/11/2023 22:31:47 - INFO - __main__ -   epoch 0 step 26300 loss 0.18338
06/11/2023 22:32:51 - INFO - __main__ -   epoch 0 step 26400 loss 0.19381
06/11/2023 22:33:54 - INFO - __main__ -   epoch 0 step 26500 loss 0.19464
06/11/2023 22:34:58 - INFO - __main__ -   epoch 0 step 26600 loss 0.19044
06/11/2023 22:36:02 - INFO - __main__ -   epoch 0 step 26700 loss 0.18991
06/11/2023 22:37:05 - INFO - __main__ -   epoch 0 step 26800 loss 0.19125
06/11/2023 22:38:09 - INFO - __main__ -   epoch 0 step 26900 loss 0.18933
06/11/2023 22:39:13 - INFO - __main__ -   epoch 0 step 27000 loss 0.18803
06/11/2023 22:40:16 - INFO - __main__ -   epoch 0 step 27100 loss 0.18552
06/11/2023 22:41:20 - INFO - __main__ -   epoch 0 step 27200 loss 0.18202
06/11/2023 22:42:24 - INFO - __main__ -   epoch 0 step 27300 loss 0.17924
06/11/2023 22:43:28 - INFO - __main__ -   epoch 0 step 27400 loss 0.17797
06/11/2023 22:44:31 - INFO - __main__ -   epoch 0 step 27500 loss 0.18358
06/11/2023 22:45:35 - INFO - __main__ -   epoch 0 step 27600 loss 0.18524
06/11/2023 22:46:39 - INFO - __main__ -   epoch 0 step 27700 loss 0.18526
06/11/2023 22:47:42 - INFO - __main__ -   epoch 0 step 27800 loss 0.18329
06/11/2023 22:48:46 - INFO - __main__ -   epoch 0 step 27900 loss 0.18253
06/11/2023 22:49:50 - INFO - __main__ -   epoch 0 step 28000 loss 0.18143
06/11/2023 22:50:53 - INFO - __main__ -   epoch 0 step 28100 loss 0.18164
06/11/2023 22:51:57 - INFO - __main__ -   epoch 0 step 28200 loss 0.17812
06/11/2023 22:53:01 - INFO - __main__ -   epoch 0 step 28300 loss 0.17715
06/11/2023 22:53:15 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 22:53:15 - INFO - __main__ -     Num examples = 9604
06/11/2023 22:53:15 - INFO - __main__ -     Batch size = 64
06/11/2023 22:58:42 - INFO - __main__ -     eval_loss = 3.5474
06/11/2023 22:58:42 - INFO - __main__ -     eval_mrr = 0.2305
06/11/2023 22:59:31 - INFO - __main__ -   epoch 0 step 28400 loss 0.19152
06/11/2023 23:00:36 - INFO - __main__ -   epoch 0 step 28500 loss 0.17921
06/11/2023 23:01:40 - INFO - __main__ -   epoch 0 step 28600 loss 0.15684
06/11/2023 23:02:44 - INFO - __main__ -   epoch 0 step 28700 loss 0.13894
06/11/2023 23:03:48 - INFO - __main__ -   epoch 0 step 28800 loss 0.14436
06/11/2023 23:04:52 - INFO - __main__ -   epoch 0 step 28900 loss 0.14369
06/11/2023 23:05:56 - INFO - __main__ -   epoch 0 step 29000 loss 0.14302
06/11/2023 23:06:59 - INFO - __main__ -   epoch 0 step 29100 loss 0.14307
06/11/2023 23:08:03 - INFO - __main__ -   epoch 0 step 29200 loss 0.14359
06/11/2023 23:09:07 - INFO - __main__ -   epoch 0 step 29300 loss 0.15102
06/11/2023 23:10:10 - INFO - __main__ -   epoch 0 step 29400 loss 0.15248
06/11/2023 23:11:14 - INFO - __main__ -   epoch 0 step 29500 loss 0.15189
06/11/2023 23:12:18 - INFO - __main__ -   epoch 0 step 29600 loss 0.14992
06/11/2023 23:13:21 - INFO - __main__ -   epoch 0 step 29700 loss 0.15445
06/11/2023 23:14:25 - INFO - __main__ -   epoch 0 step 29800 loss 0.15763
06/11/2023 23:15:29 - INFO - __main__ -   epoch 0 step 29900 loss 0.15878
06/11/2023 23:16:32 - INFO - __main__ -   epoch 0 step 30000 loss 0.16147
06/11/2023 23:17:36 - INFO - __main__ -   epoch 0 step 30100 loss 0.16316
06/11/2023 23:18:40 - INFO - __main__ -   epoch 0 step 30200 loss 0.16313
06/11/2023 23:19:43 - INFO - __main__ -   epoch 0 step 30300 loss 0.16327
06/11/2023 23:20:47 - INFO - __main__ -   epoch 0 step 30400 loss 0.16415
06/11/2023 23:21:51 - INFO - __main__ -   epoch 0 step 30500 loss 0.16469
06/11/2023 23:22:54 - INFO - __main__ -   epoch 0 step 30600 loss 0.1646
06/11/2023 23:23:58 - INFO - __main__ -   epoch 0 step 30700 loss 0.16532
06/11/2023 23:25:02 - INFO - __main__ -   epoch 0 step 30800 loss 0.16814
06/11/2023 23:26:06 - INFO - __main__ -   epoch 0 step 30900 loss 0.16898
06/11/2023 23:27:09 - INFO - __main__ -   epoch 0 step 31000 loss 0.17014
06/11/2023 23:28:13 - INFO - __main__ -   epoch 0 step 31100 loss 0.17014
06/11/2023 23:29:17 - INFO - __main__ -   epoch 0 step 31200 loss 0.16798
06/11/2023 23:30:20 - INFO - __main__ -   epoch 0 step 31300 loss 0.16683
06/11/2023 23:31:24 - INFO - __main__ -   epoch 0 step 31400 loss 0.16756
06/11/2023 23:32:09 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 23:32:09 - INFO - __main__ -     Num examples = 9604
06/11/2023 23:32:09 - INFO - __main__ -     Batch size = 64
06/11/2023 23:37:26 - INFO - __main__ -     eval_loss = 2.916
06/11/2023 23:37:26 - INFO - __main__ -     eval_mrr = 0.1938
06/11/2023 23:38:36 - INFO - __main__ -   epoch 1 step 100 loss 0.10895
06/11/2023 23:39:41 - INFO - __main__ -   epoch 1 step 200 loss 0.11201
06/11/2023 23:40:45 - INFO - __main__ -   epoch 1 step 300 loss 0.12014
06/11/2023 23:41:49 - INFO - __main__ -   epoch 1 step 400 loss 0.12661
06/11/2023 23:42:53 - INFO - __main__ -   epoch 1 step 500 loss 0.1066
06/11/2023 23:43:57 - INFO - __main__ -   epoch 1 step 600 loss 0.10346
06/11/2023 23:45:00 - INFO - __main__ -   epoch 1 step 700 loss 0.10786
06/11/2023 23:46:04 - INFO - __main__ -   epoch 1 step 800 loss 0.11265
06/11/2023 23:47:08 - INFO - __main__ -   epoch 1 step 900 loss 0.11459
06/11/2023 23:48:12 - INFO - __main__ -   epoch 1 step 1000 loss 0.11988
06/11/2023 23:49:15 - INFO - __main__ -   epoch 1 step 1100 loss 0.12857
06/11/2023 23:50:19 - INFO - __main__ -   epoch 1 step 1200 loss 0.12688
06/11/2023 23:51:23 - INFO - __main__ -   epoch 1 step 1300 loss 0.12435
06/11/2023 23:52:26 - INFO - __main__ -   epoch 1 step 1400 loss 0.12309
06/11/2023 23:53:30 - INFO - __main__ -   epoch 1 step 1500 loss 0.12023
06/11/2023 23:54:34 - INFO - __main__ -   epoch 1 step 1600 loss 0.12118
06/11/2023 23:55:38 - INFO - __main__ -   epoch 1 step 1700 loss 0.12117
06/11/2023 23:56:41 - INFO - __main__ -   epoch 1 step 1800 loss 0.11994
06/11/2023 23:57:45 - INFO - __main__ -   epoch 1 step 1900 loss 0.11846
06/11/2023 23:58:49 - INFO - __main__ -   epoch 1 step 2000 loss 0.11846
06/11/2023 23:59:52 - INFO - __main__ -   epoch 1 step 2100 loss 0.12349
06/12/2023 00:00:56 - INFO - __main__ -   epoch 1 step 2200 loss 0.12274
06/12/2023 00:02:00 - INFO - __main__ -   epoch 1 step 2300 loss 0.12152
06/12/2023 00:03:04 - INFO - __main__ -   epoch 1 step 2400 loss 0.12014
06/12/2023 00:04:07 - INFO - __main__ -   epoch 1 step 2500 loss 0.1174
06/12/2023 00:05:11 - INFO - __main__ -   epoch 1 step 2600 loss 0.11733
06/12/2023 00:06:15 - INFO - __main__ -   epoch 1 step 2700 loss 0.11612
06/12/2023 00:07:18 - INFO - __main__ -   epoch 1 step 2800 loss 0.11819
06/12/2023 00:08:22 - INFO - __main__ -   epoch 1 step 2900 loss 0.11985
06/12/2023 00:09:26 - INFO - __main__ -   epoch 1 step 3000 loss 0.11968
06/12/2023 00:10:29 - INFO - __main__ -   epoch 1 step 3100 loss 0.11948
06/12/2023 00:10:54 - INFO - __main__ -   ***** Running evaluation *****
06/12/2023 00:10:54 - INFO - __main__ -     Num examples = 9604
06/12/2023 00:10:54 - INFO - __main__ -     Batch size = 64
06/12/2023 00:16:15 - INFO - __main__ -     eval_loss = 4.3934
06/12/2023 00:16:15 - INFO - __main__ -     eval_mrr = 0.2039
06/12/2023 00:16:53 - INFO - __main__ -   epoch 1 step 3200 loss 0.11427
06/12/2023 00:17:59 - INFO - __main__ -   epoch 1 step 3300 loss 0.12283
06/12/2023 00:19:03 - INFO - __main__ -   epoch 1 step 3400 loss 0.13982
06/12/2023 00:20:07 - INFO - __main__ -   epoch 1 step 3500 loss 0.1443
06/12/2023 00:21:11 - INFO - __main__ -   epoch 1 step 3600 loss 0.14268
06/12/2023 00:22:15 - INFO - __main__ -   epoch 1 step 3700 loss 0.13624
06/12/2023 00:23:19 - INFO - __main__ -   epoch 1 step 3800 loss 0.12932
06/12/2023 00:24:22 - INFO - __main__ -   epoch 1 step 3900 loss 0.12948
06/12/2023 00:25:26 - INFO - __main__ -   epoch 1 step 4000 loss 0.13352
06/12/2023 00:26:30 - INFO - __main__ -   epoch 1 step 4100 loss 0.14318
06/12/2023 00:27:33 - INFO - __main__ -   epoch 1 step 4200 loss 0.13373
06/12/2023 00:28:37 - INFO - __main__ -   epoch 1 step 4300 loss 0.13947
06/12/2023 00:29:41 - INFO - __main__ -   epoch 1 step 4400 loss 0.13524
06/12/2023 00:30:45 - INFO - __main__ -   epoch 1 step 4500 loss 0.13229
06/12/2023 00:31:48 - INFO - __main__ -   epoch 1 step 4600 loss 0.13021
06/12/2023 00:32:52 - INFO - __main__ -   epoch 1 step 4700 loss 0.12947
06/12/2023 00:33:56 - INFO - __main__ -   epoch 1 step 4800 loss 0.13069
06/12/2023 00:34:59 - INFO - __main__ -   epoch 1 step 4900 loss 0.13118
06/12/2023 00:36:03 - INFO - __main__ -   epoch 1 step 5000 loss 0.12885
06/12/2023 00:37:07 - INFO - __main__ -   epoch 1 step 5100 loss 0.12549
06/12/2023 00:38:11 - INFO - __main__ -   epoch 1 step 5200 loss 0.12611
06/12/2023 00:39:14 - INFO - __main__ -   epoch 1 step 5300 loss 0.12541
06/12/2023 00:40:18 - INFO - __main__ -   epoch 1 step 5400 loss 0.12472
06/12/2023 00:41:22 - INFO - __main__ -   epoch 1 step 5500 loss 0.12469
06/12/2023 00:42:25 - INFO - __main__ -   epoch 1 step 5600 loss 0.12467
06/12/2023 00:43:29 - INFO - __main__ -   epoch 1 step 5700 loss 0.12478
06/12/2023 00:44:33 - INFO - __main__ -   epoch 1 step 5800 loss 0.12346
06/12/2023 00:45:36 - INFO - __main__ -   epoch 1 step 5900 loss 0.12341
06/12/2023 00:46:40 - INFO - __main__ -   epoch 1 step 6000 loss 0.12258
06/12/2023 00:47:44 - INFO - __main__ -   epoch 1 step 6100 loss 0.12255
06/12/2023 00:48:48 - INFO - __main__ -   epoch 1 step 6200 loss 0.12236
06/12/2023 00:49:42 - INFO - __main__ -   ***** Running evaluation *****
06/12/2023 00:49:42 - INFO - __main__ -     Num examples = 9604
06/12/2023 00:49:42 - INFO - __main__ -     Batch size = 64
06/12/2023 00:55:05 - INFO - __main__ -     eval_loss = 3.0395
06/12/2023 00:55:05 - INFO - __main__ -     eval_mrr = 0.2154
06/12/2023 00:55:14 - INFO - __main__ -   epoch 1 step 6300 loss 0.11625
06/12/2023 00:56:18 - INFO - __main__ -   epoch 1 step 6400 loss 0.17835
06/12/2023 00:57:23 - INFO - __main__ -   epoch 1 step 6500 loss 0.16166
06/12/2023 00:58:27 - INFO - __main__ -   epoch 1 step 6600 loss 0.14863
06/12/2023 00:59:31 - INFO - __main__ -   epoch 1 step 6700 loss 0.14703
06/12/2023 01:00:35 - INFO - __main__ -   epoch 1 step 6800 loss 0.14692
06/12/2023 01:01:39 - INFO - __main__ -   epoch 1 step 6900 loss 0.12913
06/12/2023 01:02:43 - INFO - __main__ -   epoch 1 step 7000 loss 0.12305
06/12/2023 01:03:46 - INFO - __main__ -   epoch 1 step 7100 loss 0.12212
06/12/2023 01:04:50 - INFO - __main__ -   epoch 1 step 7200 loss 0.12665
06/12/2023 01:05:54 - INFO - __main__ -   epoch 1 step 7300 loss 0.13211
06/12/2023 01:06:57 - INFO - __main__ -   epoch 1 step 7400 loss 0.13169
06/12/2023 01:08:01 - INFO - __main__ -   epoch 1 step 7500 loss 0.12402
06/12/2023 01:09:05 - INFO - __main__ -   epoch 1 step 7600 loss 0.12273
06/12/2023 01:10:08 - INFO - __main__ -   epoch 1 step 7700 loss 0.12421
06/12/2023 01:11:12 - INFO - __main__ -   epoch 1 step 7800 loss 0.12063
06/12/2023 01:12:16 - INFO - __main__ -   epoch 1 step 7900 loss 0.12169
06/12/2023 01:13:20 - INFO - __main__ -   epoch 1 step 8000 loss 0.12008
06/12/2023 01:14:23 - INFO - __main__ -   epoch 1 step 8100 loss 0.12098
06/12/2023 01:15:27 - INFO - __main__ -   epoch 1 step 8200 loss 0.12117
06/12/2023 01:16:31 - INFO - __main__ -   epoch 1 step 8300 loss 0.12005
06/12/2023 01:17:34 - INFO - __main__ -   epoch 1 step 8400 loss 0.12005
06/12/2023 01:18:38 - INFO - __main__ -   epoch 1 step 8500 loss 0.1204
06/12/2023 01:19:42 - INFO - __main__ -   epoch 1 step 8600 loss 0.11912
06/12/2023 01:20:45 - INFO - __main__ -   epoch 1 step 8700 loss 0.11681
06/12/2023 01:21:49 - INFO - __main__ -   epoch 1 step 8800 loss 0.11816
06/12/2023 01:22:53 - INFO - __main__ -   epoch 1 step 8900 loss 0.11862
06/12/2023 01:23:56 - INFO - __main__ -   epoch 1 step 9000 loss 0.11751
06/12/2023 01:25:00 - INFO - __main__ -   epoch 1 step 9100 loss 0.11881
06/12/2023 01:26:04 - INFO - __main__ -   epoch 1 step 9200 loss 0.11813
06/12/2023 01:27:07 - INFO - __main__ -   epoch 1 step 9300 loss 0.11704
06/12/2023 01:28:11 - INFO - __main__ -   epoch 1 step 9400 loss 0.11634
06/12/2023 01:28:32 - INFO - __main__ -   ***** Running evaluation *****
06/12/2023 01:28:32 - INFO - __main__ -     Num examples = 9604
06/12/2023 01:28:32 - INFO - __main__ -     Batch size = 64
06/12/2023 01:34:00 - INFO - __main__ -     eval_loss = 3.3023
06/12/2023 01:34:00 - INFO - __main__ -     eval_mrr = 0.2201
06/12/2023 01:34:43 - INFO - __main__ -   epoch 1 step 9500 loss 0.14151
06/12/2023 01:35:48 - INFO - __main__ -   epoch 1 step 9600 loss 0.1363
06/12/2023 01:36:52 - INFO - __main__ -   epoch 1 step 9700 loss 0.13122
06/12/2023 01:37:56 - INFO - __main__ -   epoch 1 step 9800 loss 0.11236
06/12/2023 01:39:00 - INFO - __main__ -   epoch 1 step 9900 loss 0.1165
06/12/2023 01:40:04 - INFO - __main__ -   epoch 1 step 10000 loss 0.11949
06/12/2023 01:41:07 - INFO - __main__ -   epoch 1 step 10100 loss 0.12151
06/12/2023 01:42:11 - INFO - __main__ -   epoch 1 step 10200 loss 0.12072
06/12/2023 01:43:15 - INFO - __main__ -   epoch 1 step 10300 loss 0.11185
06/12/2023 01:44:18 - INFO - __main__ -   epoch 1 step 10400 loss 0.10614
06/12/2023 01:45:22 - INFO - __main__ -   epoch 1 step 10500 loss 0.10581
06/12/2023 01:46:26 - INFO - __main__ -   epoch 1 step 10600 loss 0.10695
06/12/2023 01:47:29 - INFO - __main__ -   epoch 1 step 10700 loss 0.10401
06/12/2023 01:48:33 - INFO - __main__ -   epoch 1 step 10800 loss 0.10228
06/12/2023 01:49:37 - INFO - __main__ -   epoch 1 step 10900 loss 0.10385
06/12/2023 01:50:40 - INFO - __main__ -   epoch 1 step 11000 loss 0.10032
06/12/2023 01:51:44 - INFO - __main__ -   epoch 1 step 11100 loss 0.10374
06/12/2023 01:52:48 - INFO - __main__ -   epoch 1 step 11200 loss 0.10356
06/12/2023 01:53:52 - INFO - __main__ -   epoch 1 step 11300 loss 0.10388
06/12/2023 01:54:55 - INFO - __main__ -   epoch 1 step 11400 loss 0.10268
06/12/2023 01:55:59 - INFO - __main__ -   epoch 1 step 11500 loss 0.10125
06/12/2023 01:57:03 - INFO - __main__ -   epoch 1 step 11600 loss 0.09828
06/12/2023 01:58:06 - INFO - __main__ -   epoch 1 step 11700 loss 0.10016
06/12/2023 01:59:10 - INFO - __main__ -   epoch 1 step 11800 loss 0.09844
06/12/2023 02:00:14 - INFO - __main__ -   epoch 1 step 11900 loss 0.10118
06/12/2023 02:01:17 - INFO - __main__ -   epoch 1 step 12000 loss 0.10171
06/12/2023 02:02:21 - INFO - __main__ -   epoch 1 step 12100 loss 0.10057
06/12/2023 02:03:25 - INFO - __main__ -   epoch 1 step 12200 loss 0.10093
06/12/2023 02:04:28 - INFO - __main__ -   epoch 1 step 12300 loss 0.09954
06/12/2023 02:05:32 - INFO - __main__ -   epoch 1 step 12400 loss 0.10056
06/12/2023 02:06:36 - INFO - __main__ -   epoch 1 step 12500 loss 0.09892
06/12/2023 02:07:27 - INFO - __main__ -   ***** Running evaluation *****
06/12/2023 02:07:27 - INFO - __main__ -     Num examples = 9604
06/12/2023 02:07:27 - INFO - __main__ -     Batch size = 64
06/12/2023 02:12:48 - INFO - __main__ -     eval_loss = 3.117
06/12/2023 02:12:48 - INFO - __main__ -     eval_mrr = 0.2137
06/12/2023 02:13:01 - INFO - __main__ -   epoch 1 step 12600 loss 5e-05
06/12/2023 02:14:06 - INFO - __main__ -   epoch 1 step 12700 loss 0.06847
06/12/2023 02:15:10 - INFO - __main__ -   epoch 1 step 12800 loss 0.0644
06/12/2023 02:16:14 - INFO - __main__ -   epoch 1 step 12900 loss 0.06684
06/12/2023 02:17:18 - INFO - __main__ -   epoch 1 step 13000 loss 0.09387
06/12/2023 02:18:22 - INFO - __main__ -   epoch 1 step 13100 loss 0.08562
06/12/2023 02:19:26 - INFO - __main__ -   epoch 1 step 13200 loss 0.08802
06/12/2023 02:20:29 - INFO - __main__ -   epoch 1 step 13300 loss 0.09001
06/12/2023 02:21:33 - INFO - __main__ -   epoch 1 step 13400 loss 0.09574
06/12/2023 02:22:37 - INFO - __main__ -   epoch 1 step 13500 loss 0.09634
06/12/2023 02:23:40 - INFO - __main__ -   epoch 1 step 13600 loss 0.09118
06/12/2023 02:24:44 - INFO - __main__ -   epoch 1 step 13700 loss 0.08828
06/12/2023 02:25:48 - INFO - __main__ -   epoch 1 step 13800 loss 0.08679
06/12/2023 02:26:51 - INFO - __main__ -   epoch 1 step 13900 loss 0.0884
06/12/2023 02:27:55 - INFO - __main__ -   epoch 1 step 14000 loss 0.08644
06/12/2023 02:28:59 - INFO - __main__ -   epoch 1 step 14100 loss 0.08515
06/12/2023 02:30:02 - INFO - __main__ -   epoch 1 step 14200 loss 0.08453
06/12/2023 02:31:06 - INFO - __main__ -   epoch 1 step 14300 loss 0.08346
06/12/2023 02:32:10 - INFO - __main__ -   epoch 1 step 14400 loss 0.08085
06/12/2023 02:33:13 - INFO - __main__ -   epoch 1 step 14500 loss 0.08074
06/12/2023 02:34:17 - INFO - __main__ -   epoch 1 step 14600 loss 0.08301
06/12/2023 02:35:21 - INFO - __main__ -   epoch 1 step 14700 loss 0.08238
06/12/2023 02:36:25 - INFO - __main__ -   epoch 1 step 14800 loss 0.0812
06/12/2023 02:37:28 - INFO - __main__ -   epoch 1 step 14900 loss 0.08139
06/12/2023 02:38:32 - INFO - __main__ -   epoch 1 step 15000 loss 0.08166
06/12/2023 02:39:36 - INFO - __main__ -   epoch 1 step 15100 loss 0.08081
06/12/2023 02:40:39 - INFO - __main__ -   epoch 1 step 15200 loss 0.07959
06/12/2023 02:41:43 - INFO - __main__ -   epoch 1 step 15300 loss 0.07911
06/12/2023 02:42:47 - INFO - __main__ -   epoch 1 step 15400 loss 0.08153
06/12/2023 02:43:50 - INFO - __main__ -   epoch 1 step 15500 loss 0.08085
06/12/2023 02:44:54 - INFO - __main__ -   epoch 1 step 15600 loss 0.0811
06/12/2023 02:45:58 - INFO - __main__ -   epoch 1 step 15700 loss 0.08148
06/12/2023 02:46:15 - INFO - __main__ -   ***** Running evaluation *****
06/12/2023 02:46:15 - INFO - __main__ -     Num examples = 9604
06/12/2023 02:46:15 - INFO - __main__ -     Batch size = 64
06/12/2023 02:51:39 - INFO - __main__ -     eval_loss = 3.0198
06/12/2023 02:51:39 - INFO - __main__ -     eval_mrr = 0.194
06/12/2023 02:52:25 - INFO - __main__ -   epoch 1 step 15800 loss 0.07124
06/12/2023 02:53:31 - INFO - __main__ -   epoch 1 step 15900 loss 0.03856
06/12/2023 02:54:35 - INFO - __main__ -   epoch 1 step 16000 loss 0.05788
06/12/2023 02:55:39 - INFO - __main__ -   epoch 1 step 16100 loss 0.05717
06/12/2023 02:56:43 - INFO - __main__ -   epoch 1 step 16200 loss 0.0656
06/12/2023 02:57:46 - INFO - __main__ -   epoch 1 step 16300 loss 0.06959
06/12/2023 02:58:50 - INFO - __main__ -   epoch 1 step 16400 loss 0.07982
06/12/2023 02:59:54 - INFO - __main__ -   epoch 1 step 16500 loss 0.07777
06/12/2023 03:00:58 - INFO - __main__ -   epoch 1 step 16600 loss 0.07742
06/12/2023 03:02:01 - INFO - __main__ -   epoch 1 step 16700 loss 0.07836
06/12/2023 03:03:05 - INFO - __main__ -   epoch 1 step 16800 loss 0.07772
06/12/2023 03:04:09 - INFO - __main__ -   epoch 1 step 16900 loss 0.07737
06/12/2023 03:05:12 - INFO - __main__ -   epoch 1 step 17000 loss 0.07961
06/12/2023 03:06:16 - INFO - __main__ -   epoch 1 step 17100 loss 0.07784
06/12/2023 03:07:20 - INFO - __main__ -   epoch 1 step 17200 loss 0.07556
06/12/2023 03:08:23 - INFO - __main__ -   epoch 1 step 17300 loss 0.07436
06/12/2023 03:09:27 - INFO - __main__ -   epoch 1 step 17400 loss 0.08
06/12/2023 03:10:31 - INFO - __main__ -   epoch 1 step 17500 loss 0.07698
06/12/2023 03:11:34 - INFO - __main__ -   epoch 1 step 17600 loss 0.07622
06/12/2023 03:12:38 - INFO - __main__ -   epoch 1 step 17700 loss 0.07714
06/12/2023 03:13:42 - INFO - __main__ -   epoch 1 step 17800 loss 0.07634
06/12/2023 03:14:45 - INFO - __main__ -   epoch 1 step 17900 loss 0.07622
06/12/2023 03:15:49 - INFO - __main__ -   epoch 1 step 18000 loss 0.07882
06/12/2023 03:16:53 - INFO - __main__ -   epoch 1 step 18100 loss 0.07965
06/12/2023 03:17:57 - INFO - __main__ -   epoch 1 step 18200 loss 0.08092
06/12/2023 03:19:00 - INFO - __main__ -   epoch 1 step 18300 loss 0.08122
06/12/2023 03:20:04 - INFO - __main__ -   epoch 1 step 18400 loss 0.08102
06/12/2023 03:21:08 - INFO - __main__ -   epoch 1 step 18500 loss 0.08154
06/12/2023 03:22:11 - INFO - __main__ -   epoch 1 step 18600 loss 0.08152
06/12/2023 03:23:15 - INFO - __main__ -   epoch 1 step 18700 loss 0.08095
06/12/2023 03:24:19 - INFO - __main__ -   epoch 1 step 18800 loss 0.08135
06/12/2023 03:25:06 - INFO - __main__ -   ***** Running evaluation *****
06/12/2023 03:25:06 - INFO - __main__ -     Num examples = 9604
06/12/2023 03:25:06 - INFO - __main__ -     Batch size = 64
06/12/2023 03:30:36 - INFO - __main__ -     eval_loss = 2.5591
06/12/2023 03:30:36 - INFO - __main__ -     eval_mrr = 0.2436
06/12/2023 03:30:36 - INFO - __main__ -     ********************
06/12/2023 03:30:36 - INFO - __main__ -     Best mrr:0.2436
06/12/2023 03:30:36 - INFO - __main__ -     ********************
06/12/2023 03:30:38 - INFO - __main__ -   Saving model checkpoint to /disk/scratch_big/s2334723/saved_models/python_8/checkpoint-best-mrr/model.bin
06/12/2023 03:30:55 - INFO - __main__ -   epoch 1 step 18900 loss 0.00432
06/12/2023 03:31:59 - INFO - __main__ -   epoch 1 step 19000 loss 0.03886
06/12/2023 03:33:04 - INFO - __main__ -   epoch 1 step 19100 loss 0.05679
06/12/2023 03:34:08 - INFO - __main__ -   epoch 1 step 19200 loss 0.05226
06/12/2023 03:35:12 - INFO - __main__ -   epoch 1 step 19300 loss 0.0573
06/12/2023 03:36:15 - INFO - __main__ -   epoch 1 step 19400 loss 0.06637
06/12/2023 03:37:19 - INFO - __main__ -   epoch 1 step 19500 loss 0.06743
06/12/2023 03:38:23 - INFO - __main__ -   epoch 1 step 19600 loss 0.06686
06/12/2023 03:39:26 - INFO - __main__ -   epoch 1 step 19700 loss 0.07206
06/12/2023 03:40:30 - INFO - __main__ -   epoch 1 step 19800 loss 0.07192
06/12/2023 03:41:34 - INFO - __main__ -   epoch 1 step 19900 loss 0.07164
06/12/2023 03:42:37 - INFO - __main__ -   epoch 1 step 20000 loss 0.07457
06/12/2023 03:43:41 - INFO - __main__ -   epoch 1 step 20100 loss 0.07265
06/12/2023 03:44:45 - INFO - __main__ -   epoch 1 step 20200 loss 0.07359
06/12/2023 03:45:48 - INFO - __main__ -   epoch 1 step 20300 loss 0.07266
06/12/2023 03:46:52 - INFO - __main__ -   epoch 1 step 20400 loss 0.07594
06/12/2023 03:47:56 - INFO - __main__ -   epoch 1 step 20500 loss 0.07549
06/12/2023 03:49:00 - INFO - __main__ -   epoch 1 step 20600 loss 0.07513
06/12/2023 03:50:03 - INFO - __main__ -   epoch 1 step 20700 loss 0.07393
06/12/2023 03:51:07 - INFO - __main__ -   epoch 1 step 20800 loss 0.07181
06/12/2023 03:52:11 - INFO - __main__ -   epoch 1 step 20900 loss 0.07157
06/12/2023 03:53:18 - INFO - __main__ -   epoch 1 step 21000 loss 0.07279
06/12/2023 03:54:21 - INFO - __main__ -   epoch 1 step 21100 loss 0.07225
06/12/2023 03:55:25 - INFO - __main__ -   epoch 1 step 21200 loss 0.07201
06/12/2023 03:56:29 - INFO - __main__ -   epoch 1 step 21300 loss 0.0727
06/12/2023 03:57:33 - INFO - __main__ -   epoch 1 step 21400 loss 0.07259
06/12/2023 03:58:36 - INFO - __main__ -   epoch 1 step 21500 loss 0.07115
06/12/2023 03:59:40 - INFO - __main__ -   epoch 1 step 21600 loss 0.07116
06/12/2023 04:00:44 - INFO - __main__ -   epoch 1 step 21700 loss 0.07195
06/12/2023 04:01:47 - INFO - __main__ -   epoch 1 step 21800 loss 0.07142
06/12/2023 04:02:51 - INFO - __main__ -   epoch 1 step 21900 loss 0.07111
06/12/2023 04:03:55 - INFO - __main__ -   epoch 1 step 22000 loss 0.07019
06/12/2023 04:04:08 - INFO - __main__ -   ***** Running evaluation *****
06/12/2023 04:04:08 - INFO - __main__ -     Num examples = 9604
06/12/2023 04:04:08 - INFO - __main__ -     Batch size = 64
06/12/2023 04:09:26 - INFO - __main__ -     eval_loss = 2.2909
06/12/2023 04:09:26 - INFO - __main__ -     eval_mrr = 0.2769
06/12/2023 04:09:26 - INFO - __main__ -     ********************
06/12/2023 04:09:26 - INFO - __main__ -     Best mrr:0.2769
06/12/2023 04:09:26 - INFO - __main__ -     ********************
06/12/2023 04:09:29 - INFO - __main__ -   Saving model checkpoint to /disk/scratch_big/s2334723/saved_models/python_8/checkpoint-best-mrr/model.bin
06/12/2023 04:10:19 - INFO - __main__ -   epoch 1 step 22100 loss 0.05574
06/12/2023 04:11:24 - INFO - __main__ -   epoch 1 step 22200 loss 0.06961
06/12/2023 04:12:28 - INFO - __main__ -   epoch 1 step 22300 loss 0.0621
06/12/2023 04:13:32 - INFO - __main__ -   epoch 1 step 22400 loss 0.06377
06/12/2023 04:14:36 - INFO - __main__ -   epoch 1 step 22500 loss 0.06291
06/12/2023 04:15:40 - INFO - __main__ -   epoch 1 step 22600 loss 0.06724
06/12/2023 04:16:43 - INFO - __main__ -   epoch 1 step 22700 loss 0.06228
06/12/2023 04:17:47 - INFO - __main__ -   epoch 1 step 22800 loss 0.06125
06/12/2023 04:18:51 - INFO - __main__ -   epoch 1 step 22900 loss 0.06041
06/12/2023 04:19:54 - INFO - __main__ -   epoch 1 step 23000 loss 0.0687
06/12/2023 04:20:58 - INFO - __main__ -   epoch 1 step 23100 loss 0.06562
06/12/2023 04:22:02 - INFO - __main__ -   epoch 1 step 23200 loss 0.0656
06/12/2023 04:23:06 - INFO - __main__ -   epoch 1 step 23300 loss 0.06407
06/12/2023 04:24:09 - INFO - __main__ -   epoch 1 step 23400 loss 0.06372
06/12/2023 04:25:13 - INFO - __main__ -   epoch 1 step 23500 loss 0.06147
06/12/2023 04:26:17 - INFO - __main__ -   epoch 1 step 23600 loss 0.06061
06/12/2023 04:27:20 - INFO - __main__ -   epoch 1 step 23700 loss 0.06009
06/12/2023 04:28:24 - INFO - __main__ -   epoch 1 step 23800 loss 0.05969
06/12/2023 04:29:28 - INFO - __main__ -   epoch 1 step 23900 loss 0.06025
06/12/2023 04:30:32 - INFO - __main__ -   epoch 1 step 24000 loss 0.06025
06/12/2023 04:31:35 - INFO - __main__ -   epoch 1 step 24100 loss 0.05961
06/12/2023 04:32:39 - INFO - __main__ -   epoch 1 step 24200 loss 0.06283
06/12/2023 04:33:43 - INFO - __main__ -   epoch 1 step 24300 loss 0.0636
06/12/2023 04:34:46 - INFO - __main__ -   epoch 1 step 24400 loss 0.06305
06/12/2023 04:35:50 - INFO - __main__ -   epoch 1 step 24500 loss 0.06443
06/12/2023 04:36:54 - INFO - __main__ -   epoch 1 step 24600 loss 0.06675
06/12/2023 04:37:58 - INFO - __main__ -   epoch 1 step 24700 loss 0.06636
06/12/2023 04:39:01 - INFO - __main__ -   epoch 1 step 24800 loss 0.06576
06/12/2023 04:40:05 - INFO - __main__ -   epoch 1 step 24900 loss 0.06494
06/12/2023 04:41:09 - INFO - __main__ -   epoch 1 step 25000 loss 0.06589
06/12/2023 04:42:12 - INFO - __main__ -   epoch 1 step 25100 loss 0.06698
06/12/2023 04:42:56 - INFO - __main__ -   ***** Running evaluation *****
06/12/2023 04:42:56 - INFO - __main__ -     Num examples = 9604
06/12/2023 04:42:56 - INFO - __main__ -     Batch size = 64
06/12/2023 04:48:13 - INFO - __main__ -     eval_loss = 2.3284
06/12/2023 04:48:13 - INFO - __main__ -     eval_mrr = 0.2539
06/12/2023 04:48:34 - INFO - __main__ -   epoch 1 step 25200 loss 0.10918
06/12/2023 04:49:38 - INFO - __main__ -   epoch 1 step 25300 loss 0.06252
06/12/2023 04:50:43 - INFO - __main__ -   epoch 1 step 25400 loss 0.05918
06/12/2023 04:51:47 - INFO - __main__ -   epoch 1 step 25500 loss 0.06744
06/12/2023 04:52:51 - INFO - __main__ -   epoch 1 step 25600 loss 0.07514
06/12/2023 04:53:55 - INFO - __main__ -   epoch 1 step 25700 loss 0.07429
06/12/2023 04:54:58 - INFO - __main__ -   epoch 1 step 25800 loss 0.07623
06/12/2023 04:56:02 - INFO - __main__ -   epoch 1 step 25900 loss 0.07287
06/12/2023 04:57:06 - INFO - __main__ -   epoch 1 step 26000 loss 0.06911
06/12/2023 04:58:09 - INFO - __main__ -   epoch 1 step 26100 loss 0.07698
06/12/2023 04:59:13 - INFO - __main__ -   epoch 1 step 26200 loss 0.07771
06/12/2023 05:00:17 - INFO - __main__ -   epoch 1 step 26300 loss 0.07239
06/12/2023 05:01:21 - INFO - __main__ -   epoch 1 step 26400 loss 0.07215
06/12/2023 05:02:24 - INFO - __main__ -   epoch 1 step 26500 loss 0.07022
06/12/2023 05:03:28 - INFO - __main__ -   epoch 1 step 26600 loss 0.06825
06/12/2023 05:04:32 - INFO - __main__ -   epoch 1 step 26700 loss 0.06621
06/12/2023 05:05:35 - INFO - __main__ -   epoch 1 step 26800 loss 0.06325
06/12/2023 05:06:39 - INFO - __main__ -   epoch 1 step 26900 loss 0.06594
06/12/2023 05:07:43 - INFO - __main__ -   epoch 1 step 27000 loss 0.06599
06/12/2023 05:08:46 - INFO - __main__ -   epoch 1 step 27100 loss 0.06468
06/12/2023 05:09:50 - INFO - __main__ -   epoch 1 step 27200 loss 0.06542
06/12/2023 05:10:54 - INFO - __main__ -   epoch 1 step 27300 loss 0.06621
06/12/2023 05:11:57 - INFO - __main__ -   epoch 1 step 27400 loss 0.06426
06/12/2023 05:13:01 - INFO - __main__ -   epoch 1 step 27500 loss 0.06538
06/12/2023 05:14:05 - INFO - __main__ -   epoch 1 step 27600 loss 0.06556
06/12/2023 05:15:08 - INFO - __main__ -   epoch 1 step 27700 loss 0.06364
06/12/2023 05:16:12 - INFO - __main__ -   epoch 1 step 27800 loss 0.06268
06/12/2023 05:17:16 - INFO - __main__ -   epoch 1 step 27900 loss 0.0618
06/12/2023 05:18:19 - INFO - __main__ -   epoch 1 step 28000 loss 0.06158
06/12/2023 05:19:23 - INFO - __main__ -   epoch 1 step 28100 loss 0.06112
06/12/2023 05:20:27 - INFO - __main__ -   epoch 1 step 28200 loss 0.05992
06/12/2023 05:21:31 - INFO - __main__ -   epoch 1 step 28300 loss 0.05846
06/12/2023 05:21:40 - INFO - __main__ -   ***** Running evaluation *****
06/12/2023 05:21:40 - INFO - __main__ -     Num examples = 9604
06/12/2023 05:21:40 - INFO - __main__ -     Batch size = 64
06/12/2023 05:27:05 - INFO - __main__ -     eval_loss = 2.5708
06/12/2023 05:27:05 - INFO - __main__ -     eval_mrr = 0.2486
06/12/2023 05:28:00 - INFO - __main__ -   epoch 1 step 28400 loss 0.06629
06/12/2023 05:29:04 - INFO - __main__ -   epoch 1 step 28500 loss 0.03269
06/12/2023 05:30:08 - INFO - __main__ -   epoch 1 step 28600 loss 0.053
06/12/2023 05:31:12 - INFO - __main__ -   epoch 1 step 28700 loss 0.05157
06/12/2023 05:32:16 - INFO - __main__ -   epoch 1 step 28800 loss 0.05238
06/12/2023 05:33:20 - INFO - __main__ -   epoch 1 step 28900 loss 0.05325
06/12/2023 05:34:24 - INFO - __main__ -   epoch 1 step 29000 loss 0.04934
06/12/2023 05:35:27 - INFO - __main__ -   epoch 1 step 29100 loss 0.05144
06/12/2023 05:36:31 - INFO - __main__ -   epoch 1 step 29200 loss 0.05065
06/12/2023 05:37:35 - INFO - __main__ -   epoch 1 step 29300 loss 0.04943
06/12/2023 05:38:38 - INFO - __main__ -   epoch 1 step 29400 loss 0.04752
06/12/2023 05:39:42 - INFO - __main__ -   epoch 1 step 29500 loss 0.0466
06/12/2023 05:40:46 - INFO - __main__ -   epoch 1 step 29600 loss 0.04532
06/12/2023 05:41:49 - INFO - __main__ -   epoch 1 step 29700 loss 0.04818
06/12/2023 05:42:53 - INFO - __main__ -   epoch 1 step 29800 loss 0.05119
06/12/2023 05:43:57 - INFO - __main__ -   epoch 1 step 29900 loss 0.05312
06/12/2023 05:45:00 - INFO - __main__ -   epoch 1 step 30000 loss 0.0531
06/12/2023 05:46:04 - INFO - __main__ -   epoch 1 step 30100 loss 0.05404
06/12/2023 05:47:08 - INFO - __main__ -   epoch 1 step 30200 loss 0.05463
06/12/2023 05:48:12 - INFO - __main__ -   epoch 1 step 30300 loss 0.05451
06/12/2023 05:49:15 - INFO - __main__ -   epoch 1 step 30400 loss 0.05318
06/12/2023 05:50:19 - INFO - __main__ -   epoch 1 step 30500 loss 0.05154
06/12/2023 05:51:23 - INFO - __main__ -   epoch 1 step 30600 loss 0.05172
06/12/2023 05:52:26 - INFO - __main__ -   epoch 1 step 30700 loss 0.05216
06/12/2023 05:53:30 - INFO - __main__ -   epoch 1 step 30800 loss 0.05223
06/12/2023 05:54:34 - INFO - __main__ -   epoch 1 step 30900 loss 0.05176
06/12/2023 05:55:37 - INFO - __main__ -   epoch 1 step 31000 loss 0.05181
06/12/2023 05:56:41 - INFO - __main__ -   epoch 1 step 31100 loss 0.05071
06/12/2023 05:57:45 - INFO - __main__ -   epoch 1 step 31200 loss 0.05492
06/12/2023 05:58:48 - INFO - __main__ -   epoch 1 step 31300 loss 0.05526
06/12/2023 05:59:52 - INFO - __main__ -   epoch 1 step 31400 loss 0.05647
06/12/2023 06:00:32 - INFO - __main__ -   ***** Running evaluation *****
06/12/2023 06:00:32 - INFO - __main__ -     Num examples = 9604
06/12/2023 06:00:32 - INFO - __main__ -     Batch size = 64
06/12/2023 06:05:54 - INFO - __main__ -     eval_loss = 2.6134
06/12/2023 06:05:54 - INFO - __main__ -     eval_mrr = 0.2557
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:        epoch ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████
wandb:   epoch_step ▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇▇█▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▆▇▇██
wandb:    eval_loss ▂▇██▃▄▄▄▅▃█▃▄▄▃▂▁▁▂▂
wandb:     eval_mrr ▆▄▂▁▄▁▄▄▆▄▅▅▅▅▄▆█▇▇▇
wandb: example_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:     log_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁▁▁▁
wandb: scheduler_lr ▂▃▅▇███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:        epoch 1
wandb:   epoch_step 31477
wandb: example_step 503640
wandb: scheduler_lr 0.0
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2334723/codebert-search-Adv/code/wandb/offline-run-20230611_170127-4xtlzgyy
wandb: Find logs at: ./wandb/offline-run-20230611_170127-4xtlzgyy/logs


==============NVSMI LOG==============

Timestamp                                 : Sat Jun 10 19:00:05 2023
Driver Version                            : 515.105.01
CUDA Version                              : 11.7

Attached GPUs                             : 1
GPU 00000000:08:00.0
    Product Name                          : NVIDIA GeForce GTX TITAN X
    Product Brand                         : GeForce
    Product Architecture                  : Maxwell
    Display Mode                          : Disabled
    Display Active                        : Disabled
    Persistence Mode                      : Disabled
    MIG Mode
        Current                           : N/A
        Pending                           : N/A
    Accounting Mode                       : Disabled
    Accounting Mode Buffer Size           : 4000
    Driver Model
        Current                           : N/A
        Pending                           : N/A
    Serial Number                         : 0424315003984
    GPU UUID                              : GPU-6ec5ed77-4d8f-3897-a443-24f4f2df8958
    Minor Number                          : 2
    VBIOS Version                         : 84.00.45.00.90
    MultiGPU Board                        : No
    Board ID                              : 0x800
    GPU Part Number                       : N/A
    Module ID                             : 0
    Inforom Version
        Image Version                     : G001.0000.01.03
        OEM Object                        : 1.1
        ECC Object                        : N/A
        Power Management Object           : N/A
    GPU Operation Mode
        Current                           : N/A
        Pending                           : N/A
    GSP Firmware Version                  : N/A
    GPU Virtualization Mode
        Virtualization Mode               : None
        Host VGPU Mode                    : N/A
    IBMNPU
        Relaxed Ordering Mode             : N/A
    PCI
        Bus                               : 0x08
        Device                            : 0x00
        Domain                            : 0x0000
        Device Id                         : 0x17C210DE
        Bus Id                            : 00000000:08:00.0
        Sub System Id                     : 0x29923842
        GPU Link Info
            PCIe Generation
                Max                       : 3
                Current                   : 1
            Link Width
                Max                       : 16x
                Current                   : 8x
        Bridge Chip
            Type                          : N/A
            Firmware                      : N/A
        Replays Since Reset               : 0
        Replay Number Rollovers           : 0
        Tx Throughput                     : 0 KB/s
        Rx Throughput                     : 0 KB/s
    Fan Speed                             : 22 %
    Performance State                     : P8
    Clocks Throttle Reasons
        Idle                              : Active
        Applications Clocks Setting       : Not Active
        SW Power Cap                      : Not Active
        HW Slowdown                       : Not Active
            HW Thermal Slowdown           : N/A
            HW Power Brake Slowdown       : N/A
        Sync Boost                        : Not Active
        SW Thermal Slowdown               : Not Active
        Display Clock Setting             : Not Active
    FB Memory Usage
        Total                             : 12288 MiB
        Reserved                          : 75 MiB
        Used                              : 0 MiB
        Free                              : 12212 MiB
    BAR1 Memory Usage
        Total                             : 256 MiB
        Used                              : 2 MiB
        Free                              : 254 MiB
    Compute Mode                          : Default
    Utilization
        Gpu                               : 0 %
        Memory                            : 0 %
        Encoder                           : 0 %
        Decoder                           : 0 %
    Encoder Stats
        Active Sessions                   : 0
        Average FPS                       : 0
        Average Latency                   : 0
    FBC Stats
        Active Sessions                   : 0
        Average FPS                       : 0
        Average Latency                   : 0
    Ecc Mode
        Current                           : N/A
        Pending                           : N/A
    ECC Errors
        Volatile
            Single Bit            
                Device Memory             : N/A
                Register File             : N/A
                L1 Cache                  : N/A
                L2 Cache                  : N/A
                Texture Memory            : N/A
                Texture Shared            : N/A
                CBU                       : N/A
                Total                     : N/A
            Double Bit            
                Device Memory             : N/A
                Register File             : N/A
                L1 Cache                  : N/A
                L2 Cache                  : N/A
                Texture Memory            : N/A
                Texture Shared            : N/A
                CBU                       : N/A
                Total                     : N/A
        Aggregate
            Single Bit            
                Device Memory             : N/A
                Register File             : N/A
                L1 Cache                  : N/A
                L2 Cache                  : N/A
                Texture Memory            : N/A
                Texture Shared            : N/A
                CBU                       : N/A
                Total                     : N/A
            Double Bit            
                Device Memory             : N/A
                Register File             : N/A
                L1 Cache                  : N/A
                L2 Cache                  : N/A
                Texture Memory            : N/A
                Texture Shared            : N/A
                CBU                       : N/A
                Total                     : N/A
    Retired Pages
        Single Bit ECC                    : N/A
        Double Bit ECC                    : N/A
        Pending Page Blacklist            : N/A
    Remapped Rows                         : N/A
    Temperature
        GPU Current Temp                  : 28 C
        GPU Shutdown Temp                 : 97 C
        GPU Slowdown Temp                 : 92 C
        GPU Max Operating Temp            : N/A
        GPU Target Temperature            : 83 C
        Memory Current Temp               : N/A
        Memory Max Operating Temp         : N/A
    Power Readings
        Power Management                  : Supported
        Power Draw                        : 14.23 W
        Power Limit                       : 250.00 W
        Default Power Limit               : 250.00 W
        Enforced Power Limit              : 250.00 W
        Min Power Limit                   : 150.00 W
        Max Power Limit                   : 275.00 W
    Clocks
        Graphics                          : 135 MHz
        SM                                : 135 MHz
        Memory                            : 405 MHz
        Video                             : 405 MHz
    Applications Clocks
        Graphics                          : 1126 MHz
        Memory                            : 3505 MHz
    Default Applications Clocks
        Graphics                          : 1126 MHz
        Memory                            : 3505 MHz
    Max Clocks
        Graphics                          : 1519 MHz
        SM                                : 1519 MHz
        Memory                            : 3505 MHz
        Video                             : 1397 MHz
    Max Customer Boost Clocks
        Graphics                          : N/A
    Clock Policy
        Auto Boost                        : On
        Auto Boost Default                : On
    Voltage
        Graphics                          : N/A
    Processes                             : None

wandb: Tracking run with wandb version 0.15.3
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
06/10/2023 19:01:01 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
06/10/2023 19:01:04 - INFO - __main__ -   Training/evaluation parameters {'train_data_file': '/disk/scratch_big/s2334723/dataset/train.jsonl', 'output_dir': '/disk/scratch_big/s2334723/saved_models/python', 'eval_data_file': '/disk/scratch_big/s2334723/dataset/valid.jsonl', 'test_data_file': '/disk/scratch_big/s2334723/dataset/test.jsonl', 'model_type': 'roberta', 'model_name_or_path': '/disk/scratch_big/s2334723/microsoft/codebert-base', 'mlm': False, 'mlm_probability': 0.15, 'config_name': '/disk/scratch_big/s2334723/microsoft/codebert-base', 'tokenizer_name': '/disk/scratch_big/s2334723/microsoft/codebert-base', 'cache_dir': '', 'block_size': 256, 'do_train': True, 'do_eval': False, 'do_test': False, 'evaluate_during_training': True, 'do_lower_case': False, 'train_batch_size': 16, 'eval_batch_size': 64, 'gradient_accumulation_steps': 1, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 2, 'save_total_limit': None, 'eval_all_checkpoints': False, 'no_cuda': False, 'overwrite_output_dir': False, 'overwrite_cache': False, 'seed': 123456, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'server_ip': '', 'server_port': '', 'gradient_checkpointing': False, 'gpu_batch_contrasting': False, 'n_gpu': 1, 'device': 'cuda', 'per_gpu_train_batch_size': 16, 'per_gpu_eval_batch_size': 64, 'start_epoch': 0, 'start_step': 0}
06/10/2023 19:08:08 - INFO - __main__ -   *** Example ***
06/10/2023 19:08:08 - INFO - __main__ -   idx: 0
06/10/2023 19:08:08 - INFO - __main__ -   code_tokens: ['<s>', 'def', '_split', '_', 'ph', 'yl', 'ogen', 'y', '_(', '_p', '_,', '_level', '_=', '_"', 's', '"', '_)', '_:', '_level', '_=', '_level', '_+', '_"', '__', '"', '_result', '_=', '_p', '_.', '_split', '_(', '_level', '_)', '_return', '_result', '_[', '_0', '_]', '_+', '_level', '_+', '_result', '_[', '_1', '_]', '_.', '_split', '_(', '_"', ';"', '_)', '_[', '_0', '_]', '</s>']
06/10/2023 19:08:08 - INFO - __main__ -   code_ids: 0 9232 3462 1215 3792 4360 11575 219 36 181 2156 672 5457 22 29 113 4839 4832 672 5457 672 2055 22 30529 113 898 5457 181 479 3462 36 672 4839 671 898 646 321 27779 2055 672 2055 898 646 112 27779 479 3462 36 22 42777 4839 646 321 27779 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
06/10/2023 19:08:08 - INFO - __main__ -   nl_tokens: ['<s>', 'Return', '_either', '_the', '_full', '_or', '_trunc', 'ated', '_version', '_of', '_a', '_Q', 'I', 'IME', '_-', '_formatted', '_tax', 'onomy', '_string', '_.', '</s>']
06/10/2023 19:08:08 - INFO - __main__ -   nl_ids: 0 42555 1169 5 455 50 43064 1070 1732 9 10 1209 100 28417 111 46625 629 38217 6755 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
06/10/2023 19:08:08 - INFO - __main__ -   *** Example ***
06/10/2023 19:08:08 - INFO - __main__ -   idx: 1
06/10/2023 19:08:08 - INFO - __main__ -   code_tokens: ['<s>', 'def', '_ensure', '_', 'dir', '_(', '_d', '_)', '_:', '_if', '_not', '_os', '_.', '_path', '_.', '_exists', '_(', '_d', '_)', '_:', '_try', '_:', '_os', '_.', '_m', 'aked', 'irs', '_(', '_d', '_)', '_except', '_O', 'SE', 'r', 'ror', '_as', '_o', 'e', '_:', '_#', '_should', '_not', '_happen', '_with', '_os', '.', 'm', 'aked', 'irs', '_#', '_EN', 'O', 'ENT', ':', '_No', '_such', '_file', '_or', '_directory', '_if', '_os', '_.', '_err', 'no', '_==', '_err', 'no', '_.', '_EN', 'O', 'ENT', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_"""', 'One', '_or', '_more', '_directories', '_in', '_the', '_path', '_({', '})', '_do', '_not', '_exist', '.', '_If', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_you', '_are', '_specifying', '_a', '_new', '_directory', '_for', '_output', ',', '_please', '_ensure', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_all', '_other', '_directories', '_in', '_the', '_path', '_currently', '_exist', '."', '""', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_)', '_else', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_"""', 'An', '_error', '_occurred', '_trying', '_to', '_create', '_the', '_output', '_directory', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_({', '})', '_with', '_message', ':', '_{}', '"""', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_,', '_o', 'e', '_.', '_stre', 'r', 'ror', '_)', '</s>']
06/10/2023 19:08:08 - INFO - __main__ -   code_ids: 0 9232 1306 1215 41292 36 385 4839 4832 114 45 11988 479 2718 479 8785 36 385 4839 4832 860 4832 11988 479 475 8435 21098 36 385 4839 4682 384 3388 338 21929 25 1021 242 4832 849 197 45 1369 19 11988 4 119 8435 21098 849 13245 673 5382 35 440 215 2870 50 31826 114 11988 479 22379 2362 45994 22379 2362 479 13245 673 5382 4832 49049 5457 11901 16134 36 49434 3762 50 55 44472 11 5 2718 49698 49424 109 45 5152 4 318 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 47 32 39140 10 92 31826 13 4195 6 2540 1306 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 70 97 44472 11 5 2718 855 5152 72 48149 4839 671 49049 479 7390 36 385 4839 1493 4832 49049 5457 11901 16134 36 49434 4688 5849 2756 667 7 1045 5 4195 31826 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 49698 49424 19 1579 35 49153 49849 4839 671 49049 479 7390 36 385 2156 1021 242 479 22246 338 21929 4839 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
06/10/2023 19:08:08 - INFO - __main__ -   nl_tokens: ['<s>', 'Check', '_to', '_make', '_sure', '_the', '_supplied', '_directory', '_path', '_does', '_not', '_exist', '_if', '_so', '_create', '_it', '_.', '_The', '_method', '_catches', '_O', 'SE', 'r', 'ror', '_exceptions', '_and', '_returns', '_a', '_descriptive', '_message', '_instead', '_of', '_re', '_-', '_raising', '_the', '_error', '_.', '</s>']
06/10/2023 19:08:08 - INFO - __main__ -   nl_ids: 0 26615 7 146 686 5 12359 31826 2718 473 45 5152 114 98 1045 24 479 20 5448 8758 384 3388 338 21929 18286 8 2886 10 42690 1579 1386 9 769 111 3282 5 5849 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
06/10/2023 19:08:08 - INFO - __main__ -   *** Example ***
06/10/2023 19:08:08 - INFO - __main__ -   idx: 2
06/10/2023 19:08:08 - INFO - __main__ -   code_tokens: ['<s>', 'def', '_file', '_', 'handle', '_(', '_fn', 'h', '_,', '_mode', '_=', '_"', 'r', 'U', '"', '_)', '_:', '_handle', '_=', '_None', '_if', '_is', 'instance', '_(', '_fn', 'h', '_,', '_file', '_)', '_:', '_if', '_fn', 'h', '_.', '_closed', '_:', '_raise', '_Value', 'Error', '_(', '_"', 'Input', '_file', '_is', '_closed', '."', '_)', '_handle', '_=', '_fn', 'h', '_el', 'if', '_is', 'instance', '_(', '_fn', 'h', '_,', '_str', '_)', '_:', '_handle', '_=', '_open', '_(', '_fn', 'h', '_,', '_mode', '_)', '_return', '_handle', '</s>']
06/10/2023 19:08:08 - INFO - __main__ -   code_ids: 0 9232 2870 1215 26628 36 48930 298 2156 5745 5457 22 338 791 113 4839 4832 3679 5457 9291 114 16 48768 36 48930 298 2156 2870 4839 4832 114 48930 298 479 1367 4832 1693 11714 30192 36 22 48214 2870 16 1367 72 4839 3679 5457 48930 298 1615 1594 16 48768 36 48930 298 2156 7031 4839 4832 3679 5457 490 36 48930 298 2156 5745 4839 671 3679 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
06/10/2023 19:08:08 - INFO - __main__ -   nl_tokens: ['<s>', 'T', 'akes', '_either', '_a', '_file', '_path', '_or', '_an', '_open', '_file', '_handle', '_checks', '_validity', '_and', '_returns', '_an', '_open', '_file', '_handle', '_or', '_raises', '_an', '_appropriate', '_Exception', '_.', '</s>']
06/10/2023 19:08:08 - INFO - __main__ -   nl_ids: 0 565 5556 1169 10 2870 2718 50 41 490 2870 3679 6240 25295 8 2886 41 490 2870 3679 50 7700 41 3901 47617 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
/home/s2334723/micromamba/envs/ML3.8/lib/python3.8/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
06/10/2023 19:08:22 - INFO - __main__ -   ***** Running training *****
06/10/2023 19:08:22 - INFO - __main__ -     Num examples = 251820
06/10/2023 19:08:22 - INFO - __main__ -     Num Epochs = 2
06/10/2023 19:08:22 - INFO - __main__ -     Instantaneous batch size per GPU = 16
06/10/2023 19:08:22 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 16
06/10/2023 19:08:22 - INFO - __main__ -     Gradient Accumulation steps = 1
06/10/2023 19:08:22 - INFO - __main__ -     Total optimization steps = 31478
06/10/2023 19:10:27 - INFO - __main__ -   epoch 0 step 100 loss 12.21649
06/10/2023 19:12:28 - INFO - __main__ -   epoch 0 step 200 loss 8.95573
06/10/2023 19:14:29 - INFO - __main__ -   epoch 0 step 300 loss 6.8675
06/10/2023 19:16:30 - INFO - __main__ -   epoch 0 step 400 loss 5.37191
06/10/2023 19:18:31 - INFO - __main__ -   epoch 0 step 500 loss 4.38782
06/10/2023 19:20:32 - INFO - __main__ -   epoch 0 step 600 loss 3.69739
06/10/2023 19:22:34 - INFO - __main__ -   epoch 0 step 700 loss 3.20163
06/10/2023 19:24:35 - INFO - __main__ -   epoch 0 step 800 loss 2.82612
06/10/2023 19:26:36 - INFO - __main__ -   epoch 0 step 900 loss 2.53041
06/10/2023 19:28:37 - INFO - __main__ -   epoch 0 step 1000 loss 2.30114
06/10/2023 19:30:38 - INFO - __main__ -   epoch 0 step 1100 loss 2.109
06/10/2023 19:32:40 - INFO - __main__ -   epoch 0 step 1200 loss 1.94668
06/10/2023 19:34:41 - INFO - __main__ -   epoch 0 step 1300 loss 1.80817
06/10/2023 19:36:42 - INFO - __main__ -   epoch 0 step 1400 loss 1.69069
06/10/2023 19:38:43 - INFO - __main__ -   epoch 0 step 1500 loss 1.5883
06/10/2023 19:40:28 - INFO - __main__ -   ***** Running evaluation *****
06/10/2023 19:40:28 - INFO - __main__ -     Num examples = 9604
06/10/2023 19:40:28 - INFO - __main__ -     Batch size = 64
06/10/2023 19:45:51 - INFO - __main__ -     eval_loss = 1.6148
06/10/2023 19:45:51 - INFO - __main__ -     eval_mrr = 0.3041
06/10/2023 19:45:51 - INFO - __main__ -     ********************
06/10/2023 19:45:51 - INFO - __main__ -     Best mrr:0.3041
06/10/2023 19:45:51 - INFO - __main__ -     ********************
06/10/2023 19:45:54 - INFO - __main__ -   Saving model checkpoint to /disk/scratch_big/s2334723/saved_models/python/checkpoint-best-mrr/model.bin
06/10/2023 19:46:26 - INFO - __main__ -   epoch 0 step 1600 loss 0.12762
06/10/2023 19:48:27 - INFO - __main__ -   epoch 0 step 1700 loss 0.16187
06/10/2023 19:50:28 - INFO - __main__ -   epoch 0 step 1800 loss 0.17789
06/10/2023 19:52:30 - INFO - __main__ -   epoch 0 step 1900 loss 0.16119
06/10/2023 19:54:31 - INFO - __main__ -   epoch 0 step 2000 loss 0.17149
06/10/2023 19:56:32 - INFO - __main__ -   epoch 0 step 2100 loss 0.17679
06/10/2023 19:58:33 - INFO - __main__ -   epoch 0 step 2200 loss 0.18596
06/10/2023 20:00:34 - INFO - __main__ -   epoch 0 step 2300 loss 0.18255
06/10/2023 20:02:36 - INFO - __main__ -   epoch 0 step 2400 loss 0.18114
06/10/2023 20:04:37 - INFO - __main__ -   epoch 0 step 2500 loss 0.18522
06/10/2023 20:06:38 - INFO - __main__ -   epoch 0 step 2600 loss 0.18614
06/10/2023 20:08:39 - INFO - __main__ -   epoch 0 step 2700 loss 0.19028
06/10/2023 20:10:40 - INFO - __main__ -   epoch 0 step 2800 loss 0.19305
06/10/2023 20:12:42 - INFO - __main__ -   epoch 0 step 2900 loss 0.19358
06/10/2023 20:14:43 - INFO - __main__ -   epoch 0 step 3000 loss 0.19264
06/10/2023 20:16:44 - INFO - __main__ -   epoch 0 step 3100 loss 0.19684
06/10/2023 20:17:40 - INFO - __main__ -   ***** Running evaluation *****
06/10/2023 20:17:40 - INFO - __main__ -     Num examples = 9604
06/10/2023 20:17:40 - INFO - __main__ -     Batch size = 64
06/10/2023 20:23:00 - INFO - __main__ -     eval_loss = 2.3919
06/10/2023 20:23:00 - INFO - __main__ -     eval_mrr = 0.2131
06/10/2023 20:24:05 - INFO - __main__ -   epoch 0 step 3200 loss 0.29274
06/10/2023 20:26:06 - INFO - __main__ -   epoch 0 step 3300 loss 0.29636
06/10/2023 20:28:07 - INFO - __main__ -   epoch 0 step 3400 loss 0.24154
06/10/2023 20:30:09 - INFO - __main__ -   epoch 0 step 3500 loss 0.23903
06/10/2023 20:32:10 - INFO - __main__ -   epoch 0 step 3600 loss 0.23139
06/10/2023 20:34:11 - INFO - __main__ -   epoch 0 step 3700 loss 0.23428
06/10/2023 20:36:13 - INFO - __main__ -   epoch 0 step 3800 loss 0.2321
06/10/2023 20:38:14 - INFO - __main__ -   epoch 0 step 3900 loss 0.22892
06/10/2023 20:40:15 - INFO - __main__ -   epoch 0 step 4000 loss 0.22577
06/10/2023 20:42:17 - INFO - __main__ -   epoch 0 step 4100 loss 0.22646
06/10/2023 20:44:18 - INFO - __main__ -   epoch 0 step 4200 loss 0.22813
06/10/2023 20:46:19 - INFO - __main__ -   epoch 0 step 4300 loss 0.23079
06/10/2023 20:48:21 - INFO - __main__ -   epoch 0 step 4400 loss 0.22692
06/10/2023 20:50:22 - INFO - __main__ -   epoch 0 step 4500 loss 0.22616
06/10/2023 20:52:24 - INFO - __main__ -   epoch 0 step 4600 loss 0.22397
06/10/2023 20:54:25 - INFO - __main__ -   epoch 0 step 4700 loss 0.22581
06/10/2023 20:54:48 - INFO - __main__ -   ***** Running evaluation *****
06/10/2023 20:54:48 - INFO - __main__ -     Num examples = 9604
06/10/2023 20:54:48 - INFO - __main__ -     Batch size = 64
06/10/2023 21:00:16 - INFO - __main__ -     eval_loss = 2.0854
06/10/2023 21:00:16 - INFO - __main__ -     eval_mrr = 0.2297
06/10/2023 21:01:54 - INFO - __main__ -   epoch 0 step 4800 loss 0.21946
06/10/2023 21:03:55 - INFO - __main__ -   epoch 0 step 4900 loss 0.19729
06/10/2023 21:05:57 - INFO - __main__ -   epoch 0 step 5000 loss 0.1968
06/10/2023 21:07:59 - INFO - __main__ -   epoch 0 step 5100 loss 0.20906
06/10/2023 21:10:00 - INFO - __main__ -   epoch 0 step 5200 loss 0.20621
06/10/2023 21:12:02 - INFO - __main__ -   epoch 0 step 5300 loss 0.20691
06/10/2023 21:14:03 - INFO - __main__ -   epoch 0 step 5400 loss 0.21225
06/10/2023 21:16:05 - INFO - __main__ -   epoch 0 step 5500 loss 0.21276
06/10/2023 21:18:06 - INFO - __main__ -   epoch 0 step 5600 loss 0.21051
06/10/2023 21:20:08 - INFO - __main__ -   epoch 0 step 5700 loss 0.20508
06/10/2023 21:22:09 - INFO - __main__ -   epoch 0 step 5800 loss 0.20306
06/10/2023 21:24:11 - INFO - __main__ -   epoch 0 step 5900 loss 0.20604
06/10/2023 21:26:12 - INFO - __main__ -   epoch 0 step 6000 loss 0.20766
06/10/2023 21:28:14 - INFO - __main__ -   epoch 0 step 6100 loss 0.20535
06/10/2023 21:30:15 - INFO - __main__ -   epoch 0 step 6200 loss 0.20568
06/10/2023 21:32:07 - INFO - __main__ -   ***** Running evaluation *****
06/10/2023 21:32:07 - INFO - __main__ -     Num examples = 9604
06/10/2023 21:32:07 - INFO - __main__ -     Batch size = 64
06/10/2023 21:37:25 - INFO - __main__ -     eval_loss = 2.0517
06/10/2023 21:37:25 - INFO - __main__ -     eval_mrr = 0.2309
06/10/2023 21:37:35 - INFO - __main__ -   epoch 0 step 6300 loss 0.25545
06/10/2023 21:39:36 - INFO - __main__ -   epoch 0 step 6400 loss 0.22458
06/10/2023 21:41:38 - INFO - __main__ -   epoch 0 step 6500 loss 0.20733
06/10/2023 21:43:39 - INFO - __main__ -   epoch 0 step 6600 loss 0.20401
06/10/2023 21:45:40 - INFO - __main__ -   epoch 0 step 6700 loss 0.1946
06/10/2023 21:47:41 - INFO - __main__ -   epoch 0 step 6800 loss 0.2032
06/10/2023 21:49:43 - INFO - __main__ -   epoch 0 step 6900 loss 0.20256
06/10/2023 21:51:44 - INFO - __main__ -   epoch 0 step 7000 loss 0.20166
06/10/2023 21:53:45 - INFO - __main__ -   epoch 0 step 7100 loss 0.1966
06/10/2023 21:55:47 - INFO - __main__ -   epoch 0 step 7200 loss 0.19608
06/10/2023 21:57:48 - INFO - __main__ -   epoch 0 step 7300 loss 0.19785
06/10/2023 21:59:49 - INFO - __main__ -   epoch 0 step 7400 loss 0.19716
06/10/2023 22:01:51 - INFO - __main__ -   epoch 0 step 7500 loss 0.19434
06/10/2023 22:03:52 - INFO - __main__ -   epoch 0 step 7600 loss 0.19368
06/10/2023 22:05:53 - INFO - __main__ -   epoch 0 step 7700 loss 0.19402
06/10/2023 22:07:55 - INFO - __main__ -   epoch 0 step 7800 loss 0.19602
06/10/2023 22:09:14 - INFO - __main__ -   ***** Running evaluation *****
06/10/2023 22:09:14 - INFO - __main__ -     Num examples = 9604
06/10/2023 22:09:14 - INFO - __main__ -     Batch size = 64
06/10/2023 22:14:30 - INFO - __main__ -     eval_loss = 2.0865
06/10/2023 22:14:30 - INFO - __main__ -     eval_mrr = 0.2318
06/10/2023 22:15:11 - INFO - __main__ -   epoch 0 step 7900 loss 0.15811
06/10/2023 22:17:13 - INFO - __main__ -   epoch 0 step 8000 loss 0.17282
06/10/2023 22:19:14 - INFO - __main__ -   epoch 0 step 8100 loss 0.19109
06/10/2023 22:21:16 - INFO - __main__ -   epoch 0 step 8200 loss 0.20518
06/10/2023 22:23:17 - INFO - __main__ -   epoch 0 step 8300 loss 0.21363
06/10/2023 22:25:19 - INFO - __main__ -   epoch 0 step 8400 loss 0.21342
06/10/2023 22:27:20 - INFO - __main__ -   epoch 0 step 8500 loss 0.20441
06/10/2023 22:29:22 - INFO - __main__ -   epoch 0 step 8600 loss 0.19964
06/10/2023 22:31:23 - INFO - __main__ -   epoch 0 step 8700 loss 0.20069
06/10/2023 22:33:24 - INFO - __main__ -   epoch 0 step 8800 loss 0.19517
06/10/2023 22:35:26 - INFO - __main__ -   epoch 0 step 8900 loss 0.19044
06/10/2023 22:37:27 - INFO - __main__ -   epoch 0 step 9000 loss 0.18865
06/10/2023 22:39:29 - INFO - __main__ -   epoch 0 step 9100 loss 0.1866
06/10/2023 22:41:30 - INFO - __main__ -   epoch 0 step 9200 loss 0.18054
06/10/2023 22:43:31 - INFO - __main__ -   epoch 0 step 9300 loss 0.18242
06/10/2023 22:45:33 - INFO - __main__ -   epoch 0 step 9400 loss 0.18184
06/10/2023 22:46:19 - INFO - __main__ -   ***** Running evaluation *****
06/10/2023 22:46:19 - INFO - __main__ -     Num examples = 9604
06/10/2023 22:46:19 - INFO - __main__ -     Batch size = 64
06/10/2023 22:51:51 - INFO - __main__ -     eval_loss = 1.669
06/10/2023 22:51:51 - INFO - __main__ -     eval_mrr = 0.2875
06/10/2023 22:53:06 - INFO - __main__ -   epoch 0 step 9500 loss 0.18448
06/10/2023 22:55:08 - INFO - __main__ -   epoch 0 step 9600 loss 0.17085
06/10/2023 22:57:09 - INFO - __main__ -   epoch 0 step 9700 loss 0.15592
06/10/2023 22:59:10 - INFO - __main__ -   epoch 0 step 9800 loss 0.16213
06/10/2023 23:01:12 - INFO - __main__ -   epoch 0 step 9900 loss 0.16058
06/10/2023 23:03:13 - INFO - __main__ -   epoch 0 step 10000 loss 0.16705
06/10/2023 23:05:15 - INFO - __main__ -   epoch 0 step 10100 loss 0.1656
06/10/2023 23:07:16 - INFO - __main__ -   epoch 0 step 10200 loss 0.16877
06/10/2023 23:09:17 - INFO - __main__ -   epoch 0 step 10300 loss 0.17767
06/10/2023 23:11:19 - INFO - __main__ -   epoch 0 step 10400 loss 0.17573
06/10/2023 23:13:20 - INFO - __main__ -   epoch 0 step 10500 loss 0.17493
06/10/2023 23:15:22 - INFO - __main__ -   epoch 0 step 10600 loss 0.17371
06/10/2023 23:17:23 - INFO - __main__ -   epoch 0 step 10700 loss 0.17308
06/10/2023 23:19:24 - INFO - __main__ -   epoch 0 step 10800 loss 0.17042
06/10/2023 23:21:26 - INFO - __main__ -   epoch 0 step 10900 loss 0.16949
06/10/2023 23:23:27 - INFO - __main__ -   epoch 0 step 11000 loss 0.16788
06/10/2023 23:23:40 - INFO - __main__ -   ***** Running evaluation *****
06/10/2023 23:23:40 - INFO - __main__ -     Num examples = 9604
06/10/2023 23:23:40 - INFO - __main__ -     Batch size = 64
06/10/2023 23:29:07 - INFO - __main__ -     eval_loss = 1.7693
06/10/2023 23:29:07 - INFO - __main__ -     eval_mrr = 0.2707
06/10/2023 23:30:54 - INFO - __main__ -   epoch 0 step 11100 loss 0.14203
06/10/2023 23:32:56 - INFO - __main__ -   epoch 0 step 11200 loss 0.13416
06/10/2023 23:34:57 - INFO - __main__ -   epoch 0 step 11300 loss 0.14908
06/10/2023 23:36:59 - INFO - __main__ -   epoch 0 step 11400 loss 0.16144
06/10/2023 23:39:00 - INFO - __main__ -   epoch 0 step 11500 loss 0.15709
06/10/2023 23:41:01 - INFO - __main__ -   epoch 0 step 11600 loss 0.16012
06/10/2023 23:43:03 - INFO - __main__ -   epoch 0 step 11700 loss 0.15986
06/10/2023 23:45:04 - INFO - __main__ -   epoch 0 step 11800 loss 0.15568
06/10/2023 23:47:05 - INFO - __main__ -   epoch 0 step 11900 loss 0.15667
06/10/2023 23:49:07 - INFO - __main__ -   epoch 0 step 12000 loss 0.15978
06/10/2023 23:51:08 - INFO - __main__ -   epoch 0 step 12100 loss 0.15759
06/10/2023 23:53:09 - INFO - __main__ -   epoch 0 step 12200 loss 0.15434
06/10/2023 23:55:10 - INFO - __main__ -   epoch 0 step 12300 loss 0.15777
06/10/2023 23:57:12 - INFO - __main__ -   epoch 0 step 12400 loss 0.15842
06/10/2023 23:59:13 - INFO - __main__ -   epoch 0 step 12500 loss 0.15957
06/11/2023 00:00:55 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 00:00:55 - INFO - __main__ -     Num examples = 9604
06/11/2023 00:00:55 - INFO - __main__ -     Batch size = 64
06/11/2023 00:06:22 - INFO - __main__ -     eval_loss = 1.6863
06/11/2023 00:06:22 - INFO - __main__ -     eval_mrr = 0.2794
06/11/2023 00:06:41 - INFO - __main__ -   epoch 0 step 12600 loss 0.08289
06/11/2023 00:08:43 - INFO - __main__ -   epoch 0 step 12700 loss 0.095
06/11/2023 00:10:44 - INFO - __main__ -   epoch 0 step 12800 loss 0.13036
06/11/2023 00:12:45 - INFO - __main__ -   epoch 0 step 12900 loss 0.1372
06/11/2023 00:14:47 - INFO - __main__ -   epoch 0 step 13000 loss 0.13229
06/11/2023 00:16:48 - INFO - __main__ -   epoch 0 step 13100 loss 0.13825
06/11/2023 00:18:49 - INFO - __main__ -   epoch 0 step 13200 loss 0.1431
06/11/2023 00:20:51 - INFO - __main__ -   epoch 0 step 13300 loss 0.13972
06/11/2023 00:22:52 - INFO - __main__ -   epoch 0 step 13400 loss 0.138
06/11/2023 00:24:54 - INFO - __main__ -   epoch 0 step 13500 loss 0.13377
06/11/2023 00:26:55 - INFO - __main__ -   epoch 0 step 13600 loss 0.13454
06/11/2023 00:28:56 - INFO - __main__ -   epoch 0 step 13700 loss 0.13738
06/11/2023 00:30:58 - INFO - __main__ -   epoch 0 step 13800 loss 0.14161
06/11/2023 00:32:59 - INFO - __main__ -   epoch 0 step 13900 loss 0.14392
06/11/2023 00:35:00 - INFO - __main__ -   epoch 0 step 14000 loss 0.14396
06/11/2023 00:37:02 - INFO - __main__ -   epoch 0 step 14100 loss 0.14456
06/11/2023 00:38:11 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 00:38:11 - INFO - __main__ -     Num examples = 9604
06/11/2023 00:38:11 - INFO - __main__ -     Batch size = 64
06/11/2023 00:43:43 - INFO - __main__ -     eval_loss = 2.1774
06/11/2023 00:43:43 - INFO - __main__ -     eval_mrr = 0.2367
06/11/2023 00:44:34 - INFO - __main__ -   epoch 0 step 14200 loss 0.11146
06/11/2023 00:46:36 - INFO - __main__ -   epoch 0 step 14300 loss 0.14165
06/11/2023 00:48:37 - INFO - __main__ -   epoch 0 step 14400 loss 0.16064
06/11/2023 00:50:39 - INFO - __main__ -   epoch 0 step 14500 loss 0.14579
06/11/2023 00:52:40 - INFO - __main__ -   epoch 0 step 14600 loss 0.14231
06/11/2023 00:54:42 - INFO - __main__ -   epoch 0 step 14700 loss 0.139
06/11/2023 00:56:43 - INFO - __main__ -   epoch 0 step 14800 loss 0.13966
06/11/2023 00:58:45 - INFO - __main__ -   epoch 0 step 14900 loss 0.14315
06/11/2023 01:00:46 - INFO - __main__ -   epoch 0 step 15000 loss 0.13959
06/11/2023 01:02:47 - INFO - __main__ -   epoch 0 step 15100 loss 0.14238
06/11/2023 01:04:49 - INFO - __main__ -   epoch 0 step 15200 loss 0.13982
06/11/2023 01:06:50 - INFO - __main__ -   epoch 0 step 15300 loss 0.13797
06/11/2023 01:08:51 - INFO - __main__ -   epoch 0 step 15400 loss 0.13674
06/11/2023 01:10:53 - INFO - __main__ -   epoch 0 step 15500 loss 0.13501
06/11/2023 01:12:54 - INFO - __main__ -   epoch 0 step 15600 loss 0.1343
06/11/2023 01:14:55 - INFO - __main__ -   epoch 0 step 15700 loss 0.13096
06/11/2023 01:15:32 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 01:15:32 - INFO - __main__ -     Num examples = 9604
06/11/2023 01:15:32 - INFO - __main__ -     Batch size = 64
06/11/2023 01:20:50 - INFO - __main__ -     eval_loss = 2.7746
06/11/2023 01:20:50 - INFO - __main__ -     eval_mrr = 0.2345
06/11/2023 01:23:02 - INFO - __main__ -   epoch 1 step 100 loss 0.07757
06/11/2023 01:25:03 - INFO - __main__ -   epoch 1 step 200 loss 0.08467
06/11/2023 01:27:04 - INFO - __main__ -   epoch 1 step 300 loss 0.08043
06/11/2023 01:29:06 - INFO - __main__ -   epoch 1 step 400 loss 0.08917
06/11/2023 01:31:07 - INFO - __main__ -   epoch 1 step 500 loss 0.09184
06/11/2023 01:33:08 - INFO - __main__ -   epoch 1 step 600 loss 0.09008
06/11/2023 01:35:10 - INFO - __main__ -   epoch 1 step 700 loss 0.08797
06/11/2023 01:37:11 - INFO - __main__ -   epoch 1 step 800 loss 0.08591
06/11/2023 01:39:12 - INFO - __main__ -   epoch 1 step 900 loss 0.08784
06/11/2023 01:41:13 - INFO - __main__ -   epoch 1 step 1000 loss 0.0878
06/11/2023 01:43:15 - INFO - __main__ -   epoch 1 step 1100 loss 0.0914
06/11/2023 01:45:16 - INFO - __main__ -   epoch 1 step 1200 loss 0.09102
06/11/2023 01:47:18 - INFO - __main__ -   epoch 1 step 1300 loss 0.09029
06/11/2023 01:49:19 - INFO - __main__ -   epoch 1 step 1400 loss 0.09184
06/11/2023 01:51:20 - INFO - __main__ -   epoch 1 step 1500 loss 0.09146
06/11/2023 01:52:38 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 01:52:38 - INFO - __main__ -     Num examples = 9604
06/11/2023 01:52:38 - INFO - __main__ -     Batch size = 64
06/11/2023 01:57:57 - INFO - __main__ -     eval_loss = 2.2578
06/11/2023 01:57:57 - INFO - __main__ -     eval_mrr = 0.2741
06/11/2023 01:58:40 - INFO - __main__ -   epoch 1 step 1600 loss 0.09682
06/11/2023 02:00:42 - INFO - __main__ -   epoch 1 step 1700 loss 0.08274
06/11/2023 02:02:43 - INFO - __main__ -   epoch 1 step 1800 loss 0.09721
06/11/2023 02:04:44 - INFO - __main__ -   epoch 1 step 1900 loss 0.09506
06/11/2023 02:06:46 - INFO - __main__ -   epoch 1 step 2000 loss 0.10944
06/11/2023 02:08:47 - INFO - __main__ -   epoch 1 step 2100 loss 0.10931
06/11/2023 02:10:48 - INFO - __main__ -   epoch 1 step 2200 loss 0.10736
06/11/2023 02:12:50 - INFO - __main__ -   epoch 1 step 2300 loss 0.10332
06/11/2023 02:14:51 - INFO - __main__ -   epoch 1 step 2400 loss 0.10176
06/11/2023 02:16:53 - INFO - __main__ -   epoch 1 step 2500 loss 0.10323
06/11/2023 02:18:54 - INFO - __main__ -   epoch 1 step 2600 loss 0.10358
06/11/2023 02:20:55 - INFO - __main__ -   epoch 1 step 2700 loss 0.10381
06/11/2023 02:22:57 - INFO - __main__ -   epoch 1 step 2800 loss 0.1033
06/11/2023 02:24:58 - INFO - __main__ -   epoch 1 step 2900 loss 0.10308
06/11/2023 02:27:00 - INFO - __main__ -   epoch 1 step 3000 loss 0.10351
06/11/2023 02:29:01 - INFO - __main__ -   epoch 1 step 3100 loss 0.10275
06/11/2023 02:29:46 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 02:29:46 - INFO - __main__ -     Num examples = 9604
06/11/2023 02:29:46 - INFO - __main__ -     Batch size = 64
06/11/2023 02:35:04 - INFO - __main__ -     eval_loss = 2.2284
06/11/2023 02:35:04 - INFO - __main__ -     eval_mrr = 0.271
06/11/2023 02:36:20 - INFO - __main__ -   epoch 1 step 3200 loss 0.10558
06/11/2023 02:38:22 - INFO - __main__ -   epoch 1 step 3300 loss 0.09998
06/11/2023 02:40:23 - INFO - __main__ -   epoch 1 step 3400 loss 0.09745
06/11/2023 02:42:24 - INFO - __main__ -   epoch 1 step 3500 loss 0.09981
06/11/2023 02:44:26 - INFO - __main__ -   epoch 1 step 3600 loss 0.09928
06/11/2023 02:46:27 - INFO - __main__ -   epoch 1 step 3700 loss 0.09541
06/11/2023 02:48:28 - INFO - __main__ -   epoch 1 step 3800 loss 0.08967
06/11/2023 02:50:30 - INFO - __main__ -   epoch 1 step 3900 loss 0.08914
06/11/2023 02:52:31 - INFO - __main__ -   epoch 1 step 4000 loss 0.08674
06/11/2023 02:54:32 - INFO - __main__ -   epoch 1 step 4100 loss 0.08941
06/11/2023 02:56:34 - INFO - __main__ -   epoch 1 step 4200 loss 0.08726
06/11/2023 02:58:35 - INFO - __main__ -   epoch 1 step 4300 loss 0.0853
06/11/2023 03:00:36 - INFO - __main__ -   epoch 1 step 4400 loss 0.08721
06/11/2023 03:02:38 - INFO - __main__ -   epoch 1 step 4500 loss 0.08599
06/11/2023 03:04:39 - INFO - __main__ -   epoch 1 step 4600 loss 0.08837
06/11/2023 03:06:40 - INFO - __main__ -   epoch 1 step 4700 loss 0.08891
06/11/2023 03:06:52 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 03:06:52 - INFO - __main__ -     Num examples = 9604
06/11/2023 03:06:52 - INFO - __main__ -     Batch size = 64
06/11/2023 03:12:12 - INFO - __main__ -     eval_loss = 1.7707
06/11/2023 03:12:12 - INFO - __main__ -     eval_mrr = 0.2973
06/11/2023 03:14:00 - INFO - __main__ -   epoch 1 step 4800 loss 0.10349
06/11/2023 03:16:02 - INFO - __main__ -   epoch 1 step 4900 loss 0.09984
06/11/2023 03:18:03 - INFO - __main__ -   epoch 1 step 5000 loss 0.08782
06/11/2023 03:20:04 - INFO - __main__ -   epoch 1 step 5100 loss 0.08467
06/11/2023 03:22:06 - INFO - __main__ -   epoch 1 step 5200 loss 0.07684
06/11/2023 03:24:07 - INFO - __main__ -   epoch 1 step 5300 loss 0.08191
06/11/2023 03:26:09 - INFO - __main__ -   epoch 1 step 5400 loss 0.07954
06/11/2023 03:28:10 - INFO - __main__ -   epoch 1 step 5500 loss 0.08398
06/11/2023 03:30:11 - INFO - __main__ -   epoch 1 step 5600 loss 0.0844
06/11/2023 03:32:13 - INFO - __main__ -   epoch 1 step 5700 loss 0.08362
06/11/2023 03:34:14 - INFO - __main__ -   epoch 1 step 5800 loss 0.08279
06/11/2023 03:36:16 - INFO - __main__ -   epoch 1 step 5900 loss 0.0853
06/11/2023 03:38:17 - INFO - __main__ -   epoch 1 step 6000 loss 0.08602
06/11/2023 03:40:18 - INFO - __main__ -   epoch 1 step 6100 loss 0.08504
06/11/2023 03:42:20 - INFO - __main__ -   epoch 1 step 6200 loss 0.08561
06/11/2023 03:44:01 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 03:44:01 - INFO - __main__ -     Num examples = 9604
06/11/2023 03:44:01 - INFO - __main__ -     Batch size = 64
06/11/2023 03:49:23 - INFO - __main__ -     eval_loss = 2.0947
06/11/2023 03:49:23 - INFO - __main__ -     eval_mrr = 0.2906
06/11/2023 03:49:43 - INFO - __main__ -   epoch 1 step 6300 loss 0.01984
06/11/2023 03:51:45 - INFO - __main__ -   epoch 1 step 6400 loss 0.05614
06/11/2023 03:53:46 - INFO - __main__ -   epoch 1 step 6500 loss 0.07644
06/11/2023 03:55:47 - INFO - __main__ -   epoch 1 step 6600 loss 0.07974
06/11/2023 03:57:49 - INFO - __main__ -   epoch 1 step 6700 loss 0.08454
06/11/2023 03:59:50 - INFO - __main__ -   epoch 1 step 6800 loss 0.08092
06/11/2023 04:01:52 - INFO - __main__ -   epoch 1 step 6900 loss 0.07983
06/11/2023 04:03:53 - INFO - __main__ -   epoch 1 step 7000 loss 0.07937
06/11/2023 04:05:54 - INFO - __main__ -   epoch 1 step 7100 loss 0.07716
06/11/2023 04:07:56 - INFO - __main__ -   epoch 1 step 7200 loss 0.0771
06/11/2023 04:09:57 - INFO - __main__ -   epoch 1 step 7300 loss 0.07528
06/11/2023 04:11:58 - INFO - __main__ -   epoch 1 step 7400 loss 0.07379
06/11/2023 04:14:00 - INFO - __main__ -   epoch 1 step 7500 loss 0.07205
06/11/2023 04:16:01 - INFO - __main__ -   epoch 1 step 7600 loss 0.07362
06/11/2023 04:18:03 - INFO - __main__ -   epoch 1 step 7700 loss 0.07527
06/11/2023 04:20:04 - INFO - __main__ -   epoch 1 step 7800 loss 0.07339
06/11/2023 04:21:12 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 04:21:12 - INFO - __main__ -     Num examples = 9604
06/11/2023 04:21:12 - INFO - __main__ -     Batch size = 64
06/11/2023 04:26:31 - INFO - __main__ -     eval_loss = 2.1429
06/11/2023 04:26:31 - INFO - __main__ -     eval_mrr = 0.2873
06/11/2023 04:27:24 - INFO - __main__ -   epoch 1 step 7900 loss 0.07065
06/11/2023 04:29:25 - INFO - __main__ -   epoch 1 step 8000 loss 0.06114
06/11/2023 04:31:26 - INFO - __main__ -   epoch 1 step 8100 loss 0.06738
06/11/2023 04:33:28 - INFO - __main__ -   epoch 1 step 8200 loss 0.07137
06/11/2023 04:35:29 - INFO - __main__ -   epoch 1 step 8300 loss 0.06762
06/11/2023 04:37:30 - INFO - __main__ -   epoch 1 step 8400 loss 0.06891
06/11/2023 04:39:32 - INFO - __main__ -   epoch 1 step 8500 loss 0.07256
06/11/2023 04:41:33 - INFO - __main__ -   epoch 1 step 8600 loss 0.07538
06/11/2023 04:43:34 - INFO - __main__ -   epoch 1 step 8700 loss 0.07442
06/11/2023 04:45:36 - INFO - __main__ -   epoch 1 step 8800 loss 0.07337
06/11/2023 04:47:37 - INFO - __main__ -   epoch 1 step 8900 loss 0.07153
06/11/2023 04:49:38 - INFO - __main__ -   epoch 1 step 9000 loss 0.07294
06/11/2023 04:51:40 - INFO - __main__ -   epoch 1 step 9100 loss 0.07194
06/11/2023 04:53:41 - INFO - __main__ -   epoch 1 step 9200 loss 0.07293
06/11/2023 04:55:43 - INFO - __main__ -   epoch 1 step 9300 loss 0.07174
06/11/2023 04:57:44 - INFO - __main__ -   epoch 1 step 9400 loss 0.07185
06/11/2023 04:58:19 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 04:58:19 - INFO - __main__ -     Num examples = 9604
06/11/2023 04:58:19 - INFO - __main__ -     Batch size = 64
06/11/2023 05:03:43 - INFO - __main__ -     eval_loss = 2.0688
06/11/2023 05:03:43 - INFO - __main__ -     eval_mrr = 0.2921
06/11/2023 05:05:09 - INFO - __main__ -   epoch 1 step 9500 loss 0.0617
06/11/2023 05:07:10 - INFO - __main__ -   epoch 1 step 9600 loss 0.06527
06/11/2023 05:09:12 - INFO - __main__ -   epoch 1 step 9700 loss 0.07222
06/11/2023 05:11:13 - INFO - __main__ -   epoch 1 step 9800 loss 0.07147
06/11/2023 05:13:14 - INFO - __main__ -   epoch 1 step 9900 loss 0.07239
06/11/2023 05:15:16 - INFO - __main__ -   epoch 1 step 10000 loss 0.07121
06/11/2023 05:17:17 - INFO - __main__ -   epoch 1 step 10100 loss 0.07044
06/11/2023 05:19:19 - INFO - __main__ -   epoch 1 step 10200 loss 0.07197
06/11/2023 05:21:20 - INFO - __main__ -   epoch 1 step 10300 loss 0.07215
06/11/2023 05:23:22 - INFO - __main__ -   epoch 1 step 10400 loss 0.06991
06/11/2023 05:25:23 - INFO - __main__ -   epoch 1 step 10500 loss 0.06799
06/11/2023 05:27:24 - INFO - __main__ -   epoch 1 step 10600 loss 0.0676
06/11/2023 05:29:26 - INFO - __main__ -   epoch 1 step 10700 loss 0.06546
06/11/2023 05:31:27 - INFO - __main__ -   epoch 1 step 10800 loss 0.06428
06/11/2023 05:33:29 - INFO - __main__ -   epoch 1 step 10900 loss 0.06343
06/11/2023 05:35:30 - INFO - __main__ -   epoch 1 step 11000 loss 0.06325
06/11/2023 05:35:33 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 05:35:33 - INFO - __main__ -     Num examples = 9604
06/11/2023 05:35:33 - INFO - __main__ -     Batch size = 64
06/11/2023 05:40:56 - INFO - __main__ -     eval_loss = 2.04
06/11/2023 05:40:56 - INFO - __main__ -     eval_mrr = 0.295
06/11/2023 05:42:55 - INFO - __main__ -   epoch 1 step 11100 loss 0.05333
06/11/2023 05:44:56 - INFO - __main__ -   epoch 1 step 11200 loss 0.05597
06/11/2023 05:46:58 - INFO - __main__ -   epoch 1 step 11300 loss 0.06574
06/11/2023 05:48:59 - INFO - __main__ -   epoch 1 step 11400 loss 0.07022
06/11/2023 05:51:01 - INFO - __main__ -   epoch 1 step 11500 loss 0.07508
06/11/2023 05:53:02 - INFO - __main__ -   epoch 1 step 11600 loss 0.07302
06/11/2023 05:55:03 - INFO - __main__ -   epoch 1 step 11700 loss 0.07225
06/11/2023 05:57:05 - INFO - __main__ -   epoch 1 step 11800 loss 0.06883
06/11/2023 05:59:06 - INFO - __main__ -   epoch 1 step 11900 loss 0.07087
06/11/2023 06:01:07 - INFO - __main__ -   epoch 1 step 12000 loss 0.06935
06/11/2023 06:03:09 - INFO - __main__ -   epoch 1 step 12100 loss 0.06986
06/11/2023 06:05:10 - INFO - __main__ -   epoch 1 step 12200 loss 0.069
06/11/2023 06:07:12 - INFO - __main__ -   epoch 1 step 12300 loss 0.06998
06/11/2023 06:09:13 - INFO - __main__ -   epoch 1 step 12400 loss 0.06916
06/11/2023 06:11:15 - INFO - __main__ -   epoch 1 step 12500 loss 0.06925
06/11/2023 06:12:46 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 06:12:46 - INFO - __main__ -     Num examples = 9604
06/11/2023 06:12:46 - INFO - __main__ -     Batch size = 64
06/11/2023 06:18:11 - INFO - __main__ -     eval_loss = 1.7797
06/11/2023 06:18:11 - INFO - __main__ -     eval_mrr = 0.3133
06/11/2023 06:18:11 - INFO - __main__ -     ********************
06/11/2023 06:18:11 - INFO - __main__ -     Best mrr:0.3133
06/11/2023 06:18:11 - INFO - __main__ -     ********************
06/11/2023 06:18:14 - INFO - __main__ -   Saving model checkpoint to /disk/scratch_big/s2334723/saved_models/python/checkpoint-best-mrr/model.bin
06/11/2023 06:18:44 - INFO - __main__ -   epoch 1 step 12600 loss 0.05427
06/11/2023 06:20:45 - INFO - __main__ -   epoch 1 step 12700 loss 0.04471
06/11/2023 06:22:47 - INFO - __main__ -   epoch 1 step 12800 loss 0.04945
06/11/2023 06:24:48 - INFO - __main__ -   epoch 1 step 12900 loss 0.05359
06/11/2023 06:26:50 - INFO - __main__ -   epoch 1 step 13000 loss 0.05444
06/11/2023 06:28:51 - INFO - __main__ -   epoch 1 step 13100 loss 0.06215
06/11/2023 06:30:52 - INFO - __main__ -   epoch 1 step 13200 loss 0.06178
06/11/2023 06:32:54 - INFO - __main__ -   epoch 1 step 13300 loss 0.05694
06/11/2023 06:34:55 - INFO - __main__ -   epoch 1 step 13400 loss 0.05616
06/11/2023 06:36:56 - INFO - __main__ -   epoch 1 step 13500 loss 0.05732
06/11/2023 06:38:58 - INFO - __main__ -   epoch 1 step 13600 loss 0.05555
06/11/2023 06:40:59 - INFO - __main__ -   epoch 1 step 13700 loss 0.05525
06/11/2023 06:43:00 - INFO - __main__ -   epoch 1 step 13800 loss 0.0577
06/11/2023 06:45:02 - INFO - __main__ -   epoch 1 step 13900 loss 0.05764
06/11/2023 06:47:03 - INFO - __main__ -   epoch 1 step 14000 loss 0.05645
06/11/2023 06:49:04 - INFO - __main__ -   epoch 1 step 14100 loss 0.05676
06/11/2023 06:50:03 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 06:50:03 - INFO - __main__ -     Num examples = 9604
06/11/2023 06:50:03 - INFO - __main__ -     Batch size = 64
06/11/2023 06:55:28 - INFO - __main__ -     eval_loss = 1.7649
06/11/2023 06:55:28 - INFO - __main__ -     eval_mrr = 0.3202
06/11/2023 06:55:28 - INFO - __main__ -     ********************
06/11/2023 06:55:28 - INFO - __main__ -     Best mrr:0.3202
06/11/2023 06:55:28 - INFO - __main__ -     ********************
06/11/2023 06:55:30 - INFO - __main__ -   Saving model checkpoint to /disk/scratch_big/s2334723/saved_models/python/checkpoint-best-mrr/model.bin
06/11/2023 06:56:33 - INFO - __main__ -   epoch 1 step 14200 loss 0.06253
06/11/2023 06:58:35 - INFO - __main__ -   epoch 1 step 14300 loss 0.06803
06/11/2023 07:00:36 - INFO - __main__ -   epoch 1 step 14400 loss 0.0616
06/11/2023 07:02:37 - INFO - __main__ -   epoch 1 step 14500 loss 0.05787
06/11/2023 07:04:39 - INFO - __main__ -   epoch 1 step 14600 loss 0.05876
06/11/2023 07:06:40 - INFO - __main__ -   epoch 1 step 14700 loss 0.05601
06/11/2023 07:08:42 - INFO - __main__ -   epoch 1 step 14800 loss 0.0531
06/11/2023 07:10:43 - INFO - __main__ -   epoch 1 step 14900 loss 0.05388
06/11/2023 07:12:44 - INFO - __main__ -   epoch 1 step 15000 loss 0.05391
06/11/2023 07:14:46 - INFO - __main__ -   epoch 1 step 15100 loss 0.05524
06/11/2023 07:16:47 - INFO - __main__ -   epoch 1 step 15200 loss 0.05743
06/11/2023 07:18:49 - INFO - __main__ -   epoch 1 step 15300 loss 0.05957
06/11/2023 07:20:50 - INFO - __main__ -   epoch 1 step 15400 loss 0.05959
06/11/2023 07:22:51 - INFO - __main__ -   epoch 1 step 15500 loss 0.05824
06/11/2023 07:24:53 - INFO - __main__ -   epoch 1 step 15600 loss 0.05832
06/11/2023 07:26:54 - INFO - __main__ -   epoch 1 step 15700 loss 0.05916
06/11/2023 07:27:20 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 07:27:20 - INFO - __main__ -     Num examples = 9604
06/11/2023 07:27:20 - INFO - __main__ -     Batch size = 64
06/11/2023 07:32:44 - INFO - __main__ -     eval_loss = 1.7866
06/11/2023 07:32:44 - INFO - __main__ -     eval_mrr = 0.3224
06/11/2023 07:32:44 - INFO - __main__ -     ********************
06/11/2023 07:32:44 - INFO - __main__ -     Best mrr:0.3224
06/11/2023 07:32:44 - INFO - __main__ -     ********************
06/11/2023 07:32:47 - INFO - __main__ -   Saving model checkpoint to /disk/scratch_big/s2334723/saved_models/python/checkpoint-best-mrr/model.bin
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:        epoch ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████
wandb:   epoch_step ▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇▇█▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▆▇▇██
wandb:    eval_loss ▁▆▄▄▄▁▂▁▄█▅▅▂▄▄▄▄▂▂▂
wandb:     eval_mrr ▇▁▂▂▂▆▅▅▃▂▅▅▆▆▆▆▆▇██
wandb: example_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:     log_loss █▁▁▁▁▁▂▃▂▁▃▁▁▁▂▁▃▂▁▁▁▁▂▁▁▁▁▁▁▂▁▃▁▁▂▁▁▁▁▁
wandb: scheduler_lr ▂▃▅▇███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:        epoch 1
wandb:   epoch_step 15738
wandb: example_step 503640
wandb: scheduler_lr 0.0
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2334723/codebert-search-Adv/code/wandb/offline-run-20230610_190100-cgbzszaf
wandb: Find logs at: ./wandb/offline-run-20230610_190100-cgbzszaf/logs

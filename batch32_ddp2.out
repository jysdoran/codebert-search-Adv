
==============NVSMI LOG==============

Timestamp                                 : Sun Jun 11 18:36:48 2023
Driver Version                            : 515.105.01
CUDA Version                              : 11.7

Attached GPUs                             : 2
GPU 00000000:07:00.0
    Product Name                          : NVIDIA GeForce GTX TITAN X
    Product Brand                         : GeForce
    Product Architecture                  : Maxwell
    Display Mode                          : Disabled
    Display Active                        : Disabled
    Persistence Mode                      : Disabled
    MIG Mode
        Current                           : N/A
        Pending                           : N/A
    Accounting Mode                       : Disabled
    Accounting Mode Buffer Size           : 4000
    Driver Model
        Current                           : N/A
        Pending                           : N/A
    Serial Number                         : 0421116007256
    GPU UUID                              : GPU-7711a419-2a38-6b14-538a-37b3a4e17560
    Minor Number                          : 1
    VBIOS Version                         : 84.00.45.00.03
    MultiGPU Board                        : No
    Board ID                              : 0x700
    GPU Part Number                       : N/A
    Module ID                             : 0
    Inforom Version
        Image Version                     : G001.0000.01.03
        OEM Object                        : 1.1
        ECC Object                        : N/A
        Power Management Object           : N/A
    GPU Operation Mode
        Current                           : N/A
        Pending                           : N/A
    GSP Firmware Version                  : N/A
    GPU Virtualization Mode
        Virtualization Mode               : None
        Host VGPU Mode                    : N/A
    IBMNPU
        Relaxed Ordering Mode             : N/A
    PCI
        Bus                               : 0x07
        Device                            : 0x00
        Domain                            : 0x0000
        Device Id                         : 0x17C210DE
        Bus Id                            : 00000000:07:00.0
        Sub System Id                     : 0x113210DE
        GPU Link Info
            PCIe Generation
                Max                       : 3
                Current                   : 1
            Link Width
                Max                       : 16x
                Current                   : 16x
        Bridge Chip
            Type                          : N/A
            Firmware                      : N/A
        Replays Since Reset               : 0
        Replay Number Rollovers           : 0
        Tx Throughput                     : 0 KB/s
        Rx Throughput                     : 0 KB/s
    Fan Speed                             : 22 %
    Performance State                     : P8
    Clocks Throttle Reasons
        Idle                              : Active
        Applications Clocks Setting       : Not Active
        SW Power Cap                      : Not Active
        HW Slowdown                       : Not Active
            HW Thermal Slowdown           : N/A
            HW Power Brake Slowdown       : N/A
        Sync Boost                        : Not Active
        SW Thermal Slowdown               : Not Active
        Display Clock Setting             : Not Active
    FB Memory Usage
        Total                             : 12288 MiB
        Reserved                          : 75 MiB
        Used                              : 0 MiB
        Free                              : 12212 MiB
    BAR1 Memory Usage
        Total                             : 256 MiB
        Used                              : 2 MiB
        Free                              : 254 MiB
    Compute Mode                          : Default
    Utilization
        Gpu                               : 0 %
        Memory                            : 0 %
        Encoder                           : 0 %
        Decoder                           : 0 %
    Encoder Stats
        Active Sessions                   : 0
        Average FPS                       : 0
        Average Latency                   : 0
    FBC Stats
        Active Sessions                   : 0
        Average FPS                       : 0
        Average Latency                   : 0
    Ecc Mode
        Current                           : N/A
        Pending                           : N/A
    ECC Errors
        Volatile
            Single Bit            
                Device Memory             : N/A
                Register File             : N/A
                L1 Cache                  : N/A
                L2 Cache                  : N/A
                Texture Memory            : N/A
                Texture Shared            : N/A
                CBU                       : N/A
                Total                     : N/A
            Double Bit            
                Device Memory             : N/A
                Register File             : N/A
                L1 Cache                  : N/A
                L2 Cache                  : N/A
                Texture Memory            : N/A
                Texture Shared            : N/A
                CBU                       : N/A
                Total                     : N/A
        Aggregate
            Single Bit            
                Device Memory             : N/A
                Register File             : N/A
                L1 Cache                  : N/A
                L2 Cache                  : N/A
                Texture Memory            : N/A
                Texture Shared            : N/A
                CBU                       : N/A
                Total                     : N/A
            Double Bit            
                Device Memory             : N/A
                Register File             : N/A
                L1 Cache                  : N/A
                L2 Cache                  : N/A
                Texture Memory            : N/A
                Texture Shared            : N/A
                CBU                       : N/A
                Total                     : N/A
    Retired Pages
        Single Bit ECC                    : N/A
        Double Bit ECC                    : N/A
        Pending Page Blacklist            : N/A
    Remapped Rows                         : N/A
    Temperature
        GPU Current Temp                  : 26 C
        GPU Shutdown Temp                 : 97 C
        GPU Slowdown Temp                 : 92 C
        GPU Max Operating Temp            : N/A
        GPU Target Temperature            : 83 C
        Memory Current Temp               : N/A
        Memory Max Operating Temp         : N/A
    Power Readings
        Power Management                  : Supported
        Power Draw                        : 15.50 W
        Power Limit                       : 250.00 W
        Default Power Limit               : 250.00 W
        Enforced Power Limit              : 250.00 W
        Min Power Limit                   : 150.00 W
        Max Power Limit                   : 275.00 W
    Clocks
        Graphics                          : 135 MHz
        SM                                : 135 MHz
        Memory                            : 405 MHz
        Video                             : 405 MHz
    Applications Clocks
        Graphics                          : 1000 MHz
        Memory                            : 3505 MHz
    Default Applications Clocks
        Graphics                          : 1000 MHz
        Memory                            : 3505 MHz
    Max Clocks
        Graphics                          : 1392 MHz
        SM                                : 1392 MHz
        Memory                            : 3505 MHz
        Video                             : 1281 MHz
    Max Customer Boost Clocks
        Graphics                          : N/A
    Clock Policy
        Auto Boost                        : On
        Auto Boost Default                : On
    Voltage
        Graphics                          : N/A
    Processes                             : None

GPU 00000000:08:00.0
    Product Name                          : NVIDIA GeForce GTX TITAN X
    Product Brand                         : GeForce
    Product Architecture                  : Maxwell
    Display Mode                          : Disabled
    Display Active                        : Disabled
    Persistence Mode                      : Disabled
    MIG Mode
        Current                           : N/A
        Pending                           : N/A
    Accounting Mode                       : Disabled
    Accounting Mode Buffer Size           : 4000
    Driver Model
        Current                           : N/A
        Pending                           : N/A
    Serial Number                         : 0420516001212
    GPU UUID                              : GPU-e5dfb6f9-0dbc-5b89-6095-42dded9f1f69
    Minor Number                          : 2
    VBIOS Version                         : 84.00.45.00.90
    MultiGPU Board                        : No
    Board ID                              : 0x800
    GPU Part Number                       : N/A
    Module ID                             : 0
    Inforom Version
        Image Version                     : G001.0000.01.03
        OEM Object                        : 1.1
        ECC Object                        : N/A
        Power Management Object           : N/A
    GPU Operation Mode
        Current                           : N/A
        Pending                           : N/A
    GSP Firmware Version                  : N/A
    GPU Virtualization Mode
        Virtualization Mode               : None
        Host VGPU Mode                    : N/A
    IBMNPU
        Relaxed Ordering Mode             : N/A
    PCI
        Bus                               : 0x08
        Device                            : 0x00
        Domain                            : 0x0000
        Device Id                         : 0x17C210DE
        Bus Id                            : 00000000:08:00.0
        Sub System Id                     : 0x29923842
        GPU Link Info
            PCIe Generation
                Max                       : 3
                Current                   : 1
            Link Width
                Max                       : 16x
                Current                   : 16x
        Bridge Chip
            Type                          : N/A
            Firmware                      : N/A
        Replays Since Reset               : 0
        Replay Number Rollovers           : 0
        Tx Throughput                     : 0 KB/s
        Rx Throughput                     : 0 KB/s
    Fan Speed                             : 22 %
    Performance State                     : P8
    Clocks Throttle Reasons
        Idle                              : Active
        Applications Clocks Setting       : Not Active
        SW Power Cap                      : Not Active
        HW Slowdown                       : Not Active
            HW Thermal Slowdown           : N/A
            HW Power Brake Slowdown       : N/A
        Sync Boost                        : Not Active
        SW Thermal Slowdown               : Not Active
        Display Clock Setting             : Not Active
    FB Memory Usage
        Total                             : 12288 MiB
        Reserved                          : 75 MiB
        Used                              : 0 MiB
        Free                              : 12212 MiB
    BAR1 Memory Usage
        Total                             : 256 MiB
        Used                              : 2 MiB
        Free                              : 254 MiB
    Compute Mode                          : Default
    Utilization
        Gpu                               : 0 %
        Memory                            : 0 %
        Encoder                           : 0 %
        Decoder                           : 0 %
    Encoder Stats
        Active Sessions                   : 0
        Average FPS                       : 0
        Average Latency                   : 0
    FBC Stats
        Active Sessions                   : 0
        Average FPS                       : 0
        Average Latency                   : 0
    Ecc Mode
        Current                           : N/A
        Pending                           : N/A
    ECC Errors
        Volatile
            Single Bit            
                Device Memory             : N/A
                Register File             : N/A
                L1 Cache                  : N/A
                L2 Cache                  : N/A
                Texture Memory            : N/A
                Texture Shared            : N/A
                CBU                       : N/A
                Total                     : N/A
            Double Bit            
                Device Memory             : N/A
                Register File             : N/A
                L1 Cache                  : N/A
                L2 Cache                  : N/A
                Texture Memory            : N/A
                Texture Shared            : N/A
                CBU                       : N/A
                Total                     : N/A
        Aggregate
            Single Bit            
                Device Memory             : N/A
                Register File             : N/A
                L1 Cache                  : N/A
                L2 Cache                  : N/A
                Texture Memory            : N/A
                Texture Shared            : N/A
                CBU                       : N/A
                Total                     : N/A
            Double Bit            
                Device Memory             : N/A
                Register File             : N/A
                L1 Cache                  : N/A
                L2 Cache                  : N/A
                Texture Memory            : N/A
                Texture Shared            : N/A
                CBU                       : N/A
                Total                     : N/A
    Retired Pages
        Single Bit ECC                    : N/A
        Double Bit ECC                    : N/A
        Pending Page Blacklist            : N/A
    Remapped Rows                         : N/A
    Temperature
        GPU Current Temp                  : 30 C
        GPU Shutdown Temp                 : 97 C
        GPU Slowdown Temp                 : 92 C
        GPU Max Operating Temp            : N/A
        GPU Target Temperature            : 83 C
        Memory Current Temp               : N/A
        Memory Max Operating Temp         : N/A
    Power Readings
        Power Management                  : Supported
        Power Draw                        : 15.56 W
        Power Limit                       : 250.00 W
        Default Power Limit               : 250.00 W
        Enforced Power Limit              : 250.00 W
        Min Power Limit                   : 150.00 W
        Max Power Limit                   : 275.00 W
    Clocks
        Graphics                          : 135 MHz
        SM                                : 135 MHz
        Memory                            : 405 MHz
        Video                             : 405 MHz
    Applications Clocks
        Graphics                          : 1126 MHz
        Memory                            : 3505 MHz
    Default Applications Clocks
        Graphics                          : 1126 MHz
        Memory                            : 3505 MHz
    Max Clocks
        Graphics                          : 1519 MHz
        SM                                : 1519 MHz
        Memory                            : 3505 MHz
        Video                             : 1397 MHz
    Max Customer Boost Clocks
        Graphics                          : N/A
    Clock Policy
        Auto Boost                        : On
        Auto Boost Default                : On
    Voltage
        Graphics                          : N/A
    Processes                             : None

wandb: Tracking run with wandb version 0.15.3
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
06/11/2023 18:38:05 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 2, distributed training: False, 16-bits training: False
06/11/2023 18:38:08 - INFO - __main__ -   Training/evaluation parameters {'train_data_file': '/disk/scratch_big/s2334723/dataset/train.jsonl', 'output_dir': '/disk/scratch_big/s2334723/saved_models/python_ddp_32', 'eval_data_file': '/disk/scratch_big/s2334723/dataset/valid.jsonl', 'test_data_file': '/disk/scratch_big/s2334723/dataset/test.jsonl', 'model_type': 'roberta', 'model_name_or_path': '/disk/scratch_big/s2334723/microsoft/codebert-base', 'mlm': False, 'mlm_probability': 0.15, 'config_name': '/disk/scratch_big/s2334723/microsoft/codebert-base', 'tokenizer_name': '/disk/scratch_big/s2334723/microsoft/codebert-base', 'cache_dir': '', 'block_size': 256, 'do_train': True, 'do_eval': True, 'do_test': True, 'evaluate_during_training': True, 'do_lower_case': False, 'train_batch_size': 32, 'eval_batch_size': 64, 'gradient_accumulation_steps': 1, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 2, 'save_total_limit': None, 'eval_all_checkpoints': False, 'no_cuda': False, 'overwrite_output_dir': False, 'overwrite_cache': False, 'seed': 123456, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'server_ip': '', 'server_port': '', 'gradient_checkpointing': False, 'gpu_batch_contrasting': True, 'n_gpu': 2, 'device': 'cuda', 'per_gpu_train_batch_size': 16, 'per_gpu_eval_batch_size': 32, 'start_epoch': 0, 'start_step': 0}
06/11/2023 18:45:16 - INFO - __main__ -   *** Example ***
06/11/2023 18:45:16 - INFO - __main__ -   idx: 0
06/11/2023 18:45:16 - INFO - __main__ -   code_tokens: ['<s>', 'def', '_split', '_', 'ph', 'yl', 'ogen', 'y', '_(', '_p', '_,', '_level', '_=', '_"', 's', '"', '_)', '_:', '_level', '_=', '_level', '_+', '_"', '__', '"', '_result', '_=', '_p', '_.', '_split', '_(', '_level', '_)', '_return', '_result', '_[', '_0', '_]', '_+', '_level', '_+', '_result', '_[', '_1', '_]', '_.', '_split', '_(', '_"', ';"', '_)', '_[', '_0', '_]', '</s>']
06/11/2023 18:45:16 - INFO - __main__ -   code_ids: 0 9232 3462 1215 3792 4360 11575 219 36 181 2156 672 5457 22 29 113 4839 4832 672 5457 672 2055 22 30529 113 898 5457 181 479 3462 36 672 4839 671 898 646 321 27779 2055 672 2055 898 646 112 27779 479 3462 36 22 42777 4839 646 321 27779 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
06/11/2023 18:45:16 - INFO - __main__ -   nl_tokens: ['<s>', 'Return', '_either', '_the', '_full', '_or', '_trunc', 'ated', '_version', '_of', '_a', '_Q', 'I', 'IME', '_-', '_formatted', '_tax', 'onomy', '_string', '_.', '</s>']
06/11/2023 18:45:16 - INFO - __main__ -   nl_ids: 0 42555 1169 5 455 50 43064 1070 1732 9 10 1209 100 28417 111 46625 629 38217 6755 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
06/11/2023 18:45:16 - INFO - __main__ -   *** Example ***
06/11/2023 18:45:16 - INFO - __main__ -   idx: 1
06/11/2023 18:45:16 - INFO - __main__ -   code_tokens: ['<s>', 'def', '_ensure', '_', 'dir', '_(', '_d', '_)', '_:', '_if', '_not', '_os', '_.', '_path', '_.', '_exists', '_(', '_d', '_)', '_:', '_try', '_:', '_os', '_.', '_m', 'aked', 'irs', '_(', '_d', '_)', '_except', '_O', 'SE', 'r', 'ror', '_as', '_o', 'e', '_:', '_#', '_should', '_not', '_happen', '_with', '_os', '.', 'm', 'aked', 'irs', '_#', '_EN', 'O', 'ENT', ':', '_No', '_such', '_file', '_or', '_directory', '_if', '_os', '_.', '_err', 'no', '_==', '_err', 'no', '_.', '_EN', 'O', 'ENT', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_"""', 'One', '_or', '_more', '_directories', '_in', '_the', '_path', '_({', '})', '_do', '_not', '_exist', '.', '_If', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_you', '_are', '_specifying', '_a', '_new', '_directory', '_for', '_output', ',', '_please', '_ensure', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_all', '_other', '_directories', '_in', '_the', '_path', '_currently', '_exist', '."', '""', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_)', '_else', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_"""', 'An', '_error', '_occurred', '_trying', '_to', '_create', '_the', '_output', '_directory', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_({', '})', '_with', '_message', ':', '_{}', '"""', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_,', '_o', 'e', '_.', '_stre', 'r', 'ror', '_)', '</s>']
06/11/2023 18:45:16 - INFO - __main__ -   code_ids: 0 9232 1306 1215 41292 36 385 4839 4832 114 45 11988 479 2718 479 8785 36 385 4839 4832 860 4832 11988 479 475 8435 21098 36 385 4839 4682 384 3388 338 21929 25 1021 242 4832 849 197 45 1369 19 11988 4 119 8435 21098 849 13245 673 5382 35 440 215 2870 50 31826 114 11988 479 22379 2362 45994 22379 2362 479 13245 673 5382 4832 49049 5457 11901 16134 36 49434 3762 50 55 44472 11 5 2718 49698 49424 109 45 5152 4 318 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 47 32 39140 10 92 31826 13 4195 6 2540 1306 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 70 97 44472 11 5 2718 855 5152 72 48149 4839 671 49049 479 7390 36 385 4839 1493 4832 49049 5457 11901 16134 36 49434 4688 5849 2756 667 7 1045 5 4195 31826 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 49698 49424 19 1579 35 49153 49849 4839 671 49049 479 7390 36 385 2156 1021 242 479 22246 338 21929 4839 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
06/11/2023 18:45:16 - INFO - __main__ -   nl_tokens: ['<s>', 'Check', '_to', '_make', '_sure', '_the', '_supplied', '_directory', '_path', '_does', '_not', '_exist', '_if', '_so', '_create', '_it', '_.', '_The', '_method', '_catches', '_O', 'SE', 'r', 'ror', '_exceptions', '_and', '_returns', '_a', '_descriptive', '_message', '_instead', '_of', '_re', '_-', '_raising', '_the', '_error', '_.', '</s>']
06/11/2023 18:45:16 - INFO - __main__ -   nl_ids: 0 26615 7 146 686 5 12359 31826 2718 473 45 5152 114 98 1045 24 479 20 5448 8758 384 3388 338 21929 18286 8 2886 10 42690 1579 1386 9 769 111 3282 5 5849 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
06/11/2023 18:45:16 - INFO - __main__ -   *** Example ***
06/11/2023 18:45:16 - INFO - __main__ -   idx: 2
06/11/2023 18:45:16 - INFO - __main__ -   code_tokens: ['<s>', 'def', '_file', '_', 'handle', '_(', '_fn', 'h', '_,', '_mode', '_=', '_"', 'r', 'U', '"', '_)', '_:', '_handle', '_=', '_None', '_if', '_is', 'instance', '_(', '_fn', 'h', '_,', '_file', '_)', '_:', '_if', '_fn', 'h', '_.', '_closed', '_:', '_raise', '_Value', 'Error', '_(', '_"', 'Input', '_file', '_is', '_closed', '."', '_)', '_handle', '_=', '_fn', 'h', '_el', 'if', '_is', 'instance', '_(', '_fn', 'h', '_,', '_str', '_)', '_:', '_handle', '_=', '_open', '_(', '_fn', 'h', '_,', '_mode', '_)', '_return', '_handle', '</s>']
06/11/2023 18:45:16 - INFO - __main__ -   code_ids: 0 9232 2870 1215 26628 36 48930 298 2156 5745 5457 22 338 791 113 4839 4832 3679 5457 9291 114 16 48768 36 48930 298 2156 2870 4839 4832 114 48930 298 479 1367 4832 1693 11714 30192 36 22 48214 2870 16 1367 72 4839 3679 5457 48930 298 1615 1594 16 48768 36 48930 298 2156 7031 4839 4832 3679 5457 490 36 48930 298 2156 5745 4839 671 3679 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
06/11/2023 18:45:16 - INFO - __main__ -   nl_tokens: ['<s>', 'T', 'akes', '_either', '_a', '_file', '_path', '_or', '_an', '_open', '_file', '_handle', '_checks', '_validity', '_and', '_returns', '_an', '_open', '_file', '_handle', '_or', '_raises', '_an', '_appropriate', '_Exception', '_.', '</s>']
06/11/2023 18:45:16 - INFO - __main__ -   nl_ids: 0 565 5556 1169 10 2870 2718 50 41 490 2870 3679 6240 25295 8 2886 41 490 2870 3679 50 7700 41 3901 47617 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
/home/s2334723/micromamba/envs/ML3.8/lib/python3.8/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
06/11/2023 18:45:27 - INFO - __main__ -   ***** Running training *****
06/11/2023 18:45:27 - INFO - __main__ -     Num examples = 251820
06/11/2023 18:45:27 - INFO - __main__ -     Num Epochs = 2
06/11/2023 18:45:27 - INFO - __main__ -     Instantaneous batch size per GPU = 16
06/11/2023 18:45:27 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 16
06/11/2023 18:45:27 - INFO - __main__ -     Gradient Accumulation steps = 1
06/11/2023 18:45:27 - INFO - __main__ -     Total optimization steps = 15740
06/11/2023 18:47:48 - INFO - __main__ -   epoch 0 step 100 loss 12.09249
06/11/2023 18:50:06 - INFO - __main__ -   epoch 0 step 200 loss 7.92986
06/11/2023 18:52:23 - INFO - __main__ -   epoch 0 step 300 loss 5.55727
06/11/2023 18:54:39 - INFO - __main__ -   epoch 0 step 400 loss 4.24804
06/11/2023 18:56:55 - INFO - __main__ -   epoch 0 step 500 loss 3.45098
06/11/2023 18:59:14 - INFO - __main__ -   epoch 0 step 600 loss 2.91111
06/11/2023 19:01:29 - INFO - __main__ -   epoch 0 step 700 loss 2.52549
06/11/2023 19:03:43 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 19:03:43 - INFO - __main__ -     Num examples = 9604
06/11/2023 19:03:43 - INFO - __main__ -     Batch size = 64
/home/s2334723/micromamba/envs/ML3.8/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
06/11/2023 19:06:55 - INFO - __main__ -     eval_loss = 1.2187
06/11/2023 19:06:55 - INFO - __main__ -     eval_mrr = 0.26
06/11/2023 19:06:55 - INFO - __main__ -     ********************
06/11/2023 19:06:55 - INFO - __main__ -     Best mrr:0.26
06/11/2023 19:06:55 - INFO - __main__ -     ********************
06/11/2023 19:06:56 - INFO - __main__ -   Saving model checkpoint to /disk/scratch_big/s2334723/saved_models/python_ddp_32/checkpoint-best-mrr/model.bin
06/11/2023 19:07:13 - INFO - __main__ -   epoch 0 step 800 loss 0.15217
06/11/2023 19:09:30 - INFO - __main__ -   epoch 0 step 900 loss 0.18345
06/11/2023 19:11:49 - INFO - __main__ -   epoch 0 step 1000 loss 0.18377
06/11/2023 19:14:05 - INFO - __main__ -   epoch 0 step 1100 loss 0.20563
06/11/2023 19:16:20 - INFO - __main__ -   epoch 0 step 1200 loss 0.20783
06/11/2023 19:18:35 - INFO - __main__ -   epoch 0 step 1300 loss 0.20679
06/11/2023 19:20:50 - INFO - __main__ -   epoch 0 step 1400 loss 0.20955
06/11/2023 19:23:08 - INFO - __main__ -   epoch 0 step 1500 loss 0.20662
06/11/2023 19:24:47 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 19:24:47 - INFO - __main__ -     Num examples = 9604
06/11/2023 19:24:47 - INFO - __main__ -     Batch size = 64
06/11/2023 19:28:00 - INFO - __main__ -     eval_loss = 1.0478
06/11/2023 19:28:00 - INFO - __main__ -     eval_mrr = 0.3024
06/11/2023 19:28:00 - INFO - __main__ -     ********************
06/11/2023 19:28:00 - INFO - __main__ -     Best mrr:0.3024
06/11/2023 19:28:00 - INFO - __main__ -     ********************
06/11/2023 19:28:02 - INFO - __main__ -   Saving model checkpoint to /disk/scratch_big/s2334723/saved_models/python_ddp_32/checkpoint-best-mrr/model.bin
06/11/2023 19:28:36 - INFO - __main__ -   epoch 0 step 1600 loss 0.26851
06/11/2023 19:30:54 - INFO - __main__ -   epoch 0 step 1700 loss 0.23348
06/11/2023 19:33:10 - INFO - __main__ -   epoch 0 step 1800 loss 0.21797
06/11/2023 19:35:28 - INFO - __main__ -   epoch 0 step 1900 loss 0.21014
06/11/2023 19:37:43 - INFO - __main__ -   epoch 0 step 2000 loss 0.21128
06/11/2023 19:39:58 - INFO - __main__ -   epoch 0 step 2100 loss 0.21257
06/11/2023 19:42:13 - INFO - __main__ -   epoch 0 step 2200 loss 0.20985
06/11/2023 19:44:27 - INFO - __main__ -   epoch 0 step 2300 loss 0.20678
06/11/2023 19:45:49 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 19:45:49 - INFO - __main__ -     Num examples = 9604
06/11/2023 19:45:49 - INFO - __main__ -     Batch size = 64
06/11/2023 19:49:01 - INFO - __main__ -     eval_loss = 1.3042
06/11/2023 19:49:01 - INFO - __main__ -     eval_mrr = 0.2371
06/11/2023 19:49:53 - INFO - __main__ -   epoch 0 step 2400 loss 0.25512
06/11/2023 19:52:10 - INFO - __main__ -   epoch 0 step 2500 loss 0.21742
06/11/2023 19:54:26 - INFO - __main__ -   epoch 0 step 2600 loss 0.20565
06/11/2023 19:56:43 - INFO - __main__ -   epoch 0 step 2700 loss 0.21018
06/11/2023 19:58:58 - INFO - __main__ -   epoch 0 step 2800 loss 0.20395
06/11/2023 20:01:13 - INFO - __main__ -   epoch 0 step 2900 loss 0.19926
06/11/2023 20:03:27 - INFO - __main__ -   epoch 0 step 3000 loss 0.19884
06/11/2023 20:05:42 - INFO - __main__ -   epoch 0 step 3100 loss 0.20071
06/11/2023 20:06:46 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 20:06:46 - INFO - __main__ -     Num examples = 9604
06/11/2023 20:06:46 - INFO - __main__ -     Batch size = 64
06/11/2023 20:09:57 - INFO - __main__ -     eval_loss = 0.9729
06/11/2023 20:09:57 - INFO - __main__ -     eval_mrr = 0.3048
06/11/2023 20:09:57 - INFO - __main__ -     ********************
06/11/2023 20:09:57 - INFO - __main__ -     Best mrr:0.3048
06/11/2023 20:09:57 - INFO - __main__ -     ********************
06/11/2023 20:09:59 - INFO - __main__ -   Saving model checkpoint to /disk/scratch_big/s2334723/saved_models/python_ddp_32/checkpoint-best-mrr/model.bin
06/11/2023 20:11:10 - INFO - __main__ -   epoch 0 step 3200 loss 0.23057
06/11/2023 20:13:29 - INFO - __main__ -   epoch 0 step 3300 loss 0.19819
06/11/2023 20:15:44 - INFO - __main__ -   epoch 0 step 3400 loss 0.18104
06/11/2023 20:18:00 - INFO - __main__ -   epoch 0 step 3500 loss 0.18319
06/11/2023 20:20:15 - INFO - __main__ -   epoch 0 step 3600 loss 0.17865
06/11/2023 20:22:29 - INFO - __main__ -   epoch 0 step 3700 loss 0.17614
06/11/2023 20:24:46 - INFO - __main__ -   epoch 0 step 3800 loss 0.17287
06/11/2023 20:27:01 - INFO - __main__ -   epoch 0 step 3900 loss 0.17537
06/11/2023 20:27:48 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 20:27:48 - INFO - __main__ -     Num examples = 9604
06/11/2023 20:27:48 - INFO - __main__ -     Batch size = 64
06/11/2023 20:31:01 - INFO - __main__ -     eval_loss = 0.9142
06/11/2023 20:31:01 - INFO - __main__ -     eval_mrr = 0.295
06/11/2023 20:32:29 - INFO - __main__ -   epoch 0 step 4000 loss 0.12969
06/11/2023 20:34:48 - INFO - __main__ -   epoch 0 step 4100 loss 0.16684
06/11/2023 20:37:04 - INFO - __main__ -   epoch 0 step 4200 loss 0.16088
06/11/2023 20:39:19 - INFO - __main__ -   epoch 0 step 4300 loss 0.164
06/11/2023 20:41:34 - INFO - __main__ -   epoch 0 step 4400 loss 0.16723
06/11/2023 20:43:49 - INFO - __main__ -   epoch 0 step 4500 loss 0.16642
06/11/2023 20:46:07 - INFO - __main__ -   epoch 0 step 4600 loss 0.16098
06/11/2023 20:48:22 - INFO - __main__ -   epoch 0 step 4700 loss 0.15951
06/11/2023 20:48:52 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 20:48:52 - INFO - __main__ -     Num examples = 9604
06/11/2023 20:48:52 - INFO - __main__ -     Batch size = 64
06/11/2023 20:51:58 - INFO - __main__ -     eval_loss = 1.0065
06/11/2023 20:51:58 - INFO - __main__ -     eval_mrr = 0.2872
06/11/2023 20:53:45 - INFO - __main__ -   epoch 0 step 4800 loss 0.14103
06/11/2023 20:56:05 - INFO - __main__ -   epoch 0 step 4900 loss 0.14033
06/11/2023 20:58:21 - INFO - __main__ -   epoch 0 step 5000 loss 0.14839
06/11/2023 21:00:38 - INFO - __main__ -   epoch 0 step 5100 loss 0.15055
06/11/2023 21:02:53 - INFO - __main__ -   epoch 0 step 5200 loss 0.15041
06/11/2023 21:05:09 - INFO - __main__ -   epoch 0 step 5300 loss 0.15103
06/11/2023 21:07:27 - INFO - __main__ -   epoch 0 step 5400 loss 0.15145
06/11/2023 21:09:43 - INFO - __main__ -   epoch 0 step 5500 loss 0.14817
06/11/2023 21:09:55 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 21:09:55 - INFO - __main__ -     Num examples = 9604
06/11/2023 21:09:55 - INFO - __main__ -     Batch size = 64
06/11/2023 21:13:11 - INFO - __main__ -     eval_loss = 0.9196
06/11/2023 21:13:11 - INFO - __main__ -     eval_mrr = 0.2971
06/11/2023 21:15:16 - INFO - __main__ -   epoch 0 step 5600 loss 0.13491
06/11/2023 21:17:36 - INFO - __main__ -   epoch 0 step 5700 loss 0.14765
06/11/2023 21:19:53 - INFO - __main__ -   epoch 0 step 5800 loss 0.14587
06/11/2023 21:22:09 - INFO - __main__ -   epoch 0 step 5900 loss 0.13997
06/11/2023 21:24:25 - INFO - __main__ -   epoch 0 step 6000 loss 0.13998
06/11/2023 21:26:42 - INFO - __main__ -   epoch 0 step 6100 loss 0.14508
06/11/2023 21:28:58 - INFO - __main__ -   epoch 0 step 6200 loss 0.14306
06/11/2023 21:31:09 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 21:31:09 - INFO - __main__ -     Num examples = 9604
06/11/2023 21:31:09 - INFO - __main__ -     Batch size = 64
06/11/2023 21:34:24 - INFO - __main__ -     eval_loss = 0.8648
06/11/2023 21:34:24 - INFO - __main__ -     eval_mrr = 0.326
06/11/2023 21:34:24 - INFO - __main__ -     ********************
06/11/2023 21:34:24 - INFO - __main__ -     Best mrr:0.326
06/11/2023 21:34:24 - INFO - __main__ -     ********************
06/11/2023 21:34:26 - INFO - __main__ -   Saving model checkpoint to /disk/scratch_big/s2334723/saved_models/python_ddp_32/checkpoint-best-mrr/model.bin
06/11/2023 21:34:31 - INFO - __main__ -   epoch 0 step 6300 loss 0.0243
06/11/2023 21:36:48 - INFO - __main__ -   epoch 0 step 6400 loss 0.12881
06/11/2023 21:39:07 - INFO - __main__ -   epoch 0 step 6500 loss 0.13406
06/11/2023 21:41:23 - INFO - __main__ -   epoch 0 step 6600 loss 0.14331
06/11/2023 21:43:38 - INFO - __main__ -   epoch 0 step 6700 loss 0.13899
06/11/2023 21:45:54 - INFO - __main__ -   epoch 0 step 6800 loss 0.13706
06/11/2023 21:48:09 - INFO - __main__ -   epoch 0 step 6900 loss 0.13762
06/11/2023 21:50:24 - INFO - __main__ -   epoch 0 step 7000 loss 0.13515
06/11/2023 21:52:16 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 21:52:16 - INFO - __main__ -     Num examples = 9604
06/11/2023 21:52:16 - INFO - __main__ -     Batch size = 64
06/11/2023 21:55:30 - INFO - __main__ -     eval_loss = 0.8581
06/11/2023 21:55:30 - INFO - __main__ -     eval_mrr = 0.3256
06/11/2023 21:55:52 - INFO - __main__ -   epoch 0 step 7100 loss 0.16016
06/11/2023 21:58:10 - INFO - __main__ -   epoch 0 step 7200 loss 0.13577
06/11/2023 22:00:29 - INFO - __main__ -   epoch 0 step 7300 loss 0.13177
06/11/2023 22:02:45 - INFO - __main__ -   epoch 0 step 7400 loss 0.12365
06/11/2023 22:05:00 - INFO - __main__ -   epoch 0 step 7500 loss 0.12605
06/11/2023 22:07:16 - INFO - __main__ -   epoch 0 step 7600 loss 0.12368
06/11/2023 22:09:31 - INFO - __main__ -   epoch 0 step 7700 loss 0.12178
06/11/2023 22:11:46 - INFO - __main__ -   epoch 0 step 7800 loss 0.12281
06/11/2023 22:13:20 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 22:13:20 - INFO - __main__ -     Num examples = 9604
06/11/2023 22:13:20 - INFO - __main__ -     Batch size = 64
06/11/2023 22:16:34 - INFO - __main__ -     eval_loss = 0.9122
06/11/2023 22:16:34 - INFO - __main__ -     eval_mrr = 0.3138
06/11/2023 22:18:51 - INFO - __main__ -   epoch 1 step 100 loss 0.0839
06/11/2023 22:21:07 - INFO - __main__ -   epoch 1 step 200 loss 0.07396
06/11/2023 22:23:26 - INFO - __main__ -   epoch 1 step 300 loss 0.07338
06/11/2023 22:25:41 - INFO - __main__ -   epoch 1 step 400 loss 0.0724
06/11/2023 22:27:57 - INFO - __main__ -   epoch 1 step 500 loss 0.07511
06/11/2023 22:30:12 - INFO - __main__ -   epoch 1 step 600 loss 0.08004
06/11/2023 22:32:27 - INFO - __main__ -   epoch 1 step 700 loss 0.07901
06/11/2023 22:34:25 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 22:34:25 - INFO - __main__ -     Num examples = 9604
06/11/2023 22:34:25 - INFO - __main__ -     Batch size = 64
06/11/2023 22:37:38 - INFO - __main__ -     eval_loss = 0.9855
06/11/2023 22:37:38 - INFO - __main__ -     eval_mrr = 0.3186
06/11/2023 22:37:54 - INFO - __main__ -   epoch 1 step 800 loss 0.03793
06/11/2023 22:40:12 - INFO - __main__ -   epoch 1 step 900 loss 0.08567
06/11/2023 22:42:28 - INFO - __main__ -   epoch 1 step 1000 loss 0.09064
06/11/2023 22:44:44 - INFO - __main__ -   epoch 1 step 1100 loss 0.09032
06/11/2023 22:47:00 - INFO - __main__ -   epoch 1 step 1200 loss 0.08535
06/11/2023 22:49:15 - INFO - __main__ -   epoch 1 step 1300 loss 0.08543
06/11/2023 22:51:30 - INFO - __main__ -   epoch 1 step 1400 loss 0.08284
06/11/2023 22:53:45 - INFO - __main__ -   epoch 1 step 1500 loss 0.08296
06/11/2023 22:55:25 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 22:55:25 - INFO - __main__ -     Num examples = 9604
06/11/2023 22:55:25 - INFO - __main__ -     Batch size = 64
06/11/2023 22:58:39 - INFO - __main__ -     eval_loss = 1.0744
06/11/2023 22:58:39 - INFO - __main__ -     eval_mrr = 0.3147
06/11/2023 22:59:13 - INFO - __main__ -   epoch 1 step 1600 loss 0.13387
06/11/2023 23:01:34 - INFO - __main__ -   epoch 1 step 1700 loss 0.09682
06/11/2023 23:03:50 - INFO - __main__ -   epoch 1 step 1800 loss 0.08145
06/11/2023 23:06:06 - INFO - __main__ -   epoch 1 step 1900 loss 0.08189
06/11/2023 23:08:22 - INFO - __main__ -   epoch 1 step 2000 loss 0.08086
06/11/2023 23:10:37 - INFO - __main__ -   epoch 1 step 2100 loss 0.08305
06/11/2023 23:12:52 - INFO - __main__ -   epoch 1 step 2200 loss 0.08422
06/11/2023 23:15:07 - INFO - __main__ -   epoch 1 step 2300 loss 0.08462
06/11/2023 23:16:30 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 23:16:30 - INFO - __main__ -     Num examples = 9604
06/11/2023 23:16:30 - INFO - __main__ -     Batch size = 64
06/11/2023 23:19:44 - INFO - __main__ -     eval_loss = 1.0284
06/11/2023 23:19:44 - INFO - __main__ -     eval_mrr = 0.3273
06/11/2023 23:19:44 - INFO - __main__ -     ********************
06/11/2023 23:19:44 - INFO - __main__ -     Best mrr:0.3273
06/11/2023 23:19:44 - INFO - __main__ -     ********************
06/11/2023 23:19:46 - INFO - __main__ -   Saving model checkpoint to /disk/scratch_big/s2334723/saved_models/python_ddp_32/checkpoint-best-mrr/model.bin
06/11/2023 23:20:39 - INFO - __main__ -   epoch 1 step 2400 loss 0.07363
06/11/2023 23:22:57 - INFO - __main__ -   epoch 1 step 2500 loss 0.08299
06/11/2023 23:25:13 - INFO - __main__ -   epoch 1 step 2600 loss 0.07819
06/11/2023 23:27:32 - INFO - __main__ -   epoch 1 step 2700 loss 0.07773
06/11/2023 23:29:48 - INFO - __main__ -   epoch 1 step 2800 loss 0.0787
06/11/2023 23:32:03 - INFO - __main__ -   epoch 1 step 2900 loss 0.07899
06/11/2023 23:34:19 - INFO - __main__ -   epoch 1 step 3000 loss 0.08205
06/11/2023 23:36:34 - INFO - __main__ -   epoch 1 step 3100 loss 0.08053
06/11/2023 23:37:39 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 23:37:39 - INFO - __main__ -     Num examples = 9604
06/11/2023 23:37:39 - INFO - __main__ -     Batch size = 64
06/11/2023 23:40:54 - INFO - __main__ -     eval_loss = 1.1508
06/11/2023 23:40:54 - INFO - __main__ -     eval_mrr = 0.3093
06/11/2023 23:42:07 - INFO - __main__ -   epoch 1 step 3200 loss 0.07305
06/11/2023 23:44:25 - INFO - __main__ -   epoch 1 step 3300 loss 0.07558
06/11/2023 23:46:42 - INFO - __main__ -   epoch 1 step 3400 loss 0.07458
06/11/2023 23:48:58 - INFO - __main__ -   epoch 1 step 3500 loss 0.06892
06/11/2023 23:51:13 - INFO - __main__ -   epoch 1 step 3600 loss 0.06785
06/11/2023 23:53:29 - INFO - __main__ -   epoch 1 step 3700 loss 0.07168
06/11/2023 23:55:47 - INFO - __main__ -   epoch 1 step 3800 loss 0.07262
06/11/2023 23:58:03 - INFO - __main__ -   epoch 1 step 3900 loss 0.07218
06/11/2023 23:58:50 - INFO - __main__ -   ***** Running evaluation *****
06/11/2023 23:58:50 - INFO - __main__ -     Num examples = 9604
06/11/2023 23:58:50 - INFO - __main__ -     Batch size = 64
06/12/2023 00:02:05 - INFO - __main__ -     eval_loss = 0.8723
06/12/2023 00:02:05 - INFO - __main__ -     eval_mrr = 0.3629
06/12/2023 00:02:05 - INFO - __main__ -     ********************
06/12/2023 00:02:05 - INFO - __main__ -     Best mrr:0.3629
06/12/2023 00:02:05 - INFO - __main__ -     ********************
06/12/2023 00:02:08 - INFO - __main__ -   Saving model checkpoint to /disk/scratch_big/s2334723/saved_models/python_ddp_32/checkpoint-best-mrr/model.bin
06/12/2023 00:03:36 - INFO - __main__ -   epoch 1 step 4000 loss 0.04626
06/12/2023 00:05:53 - INFO - __main__ -   epoch 1 step 4100 loss 0.06544
06/12/2023 00:08:09 - INFO - __main__ -   epoch 1 step 4200 loss 0.06403
06/12/2023 00:10:25 - INFO - __main__ -   epoch 1 step 4300 loss 0.06571
06/12/2023 00:12:41 - INFO - __main__ -   epoch 1 step 4400 loss 0.06801
06/12/2023 00:14:56 - INFO - __main__ -   epoch 1 step 4500 loss 0.06948
06/12/2023 00:17:11 - INFO - __main__ -   epoch 1 step 4600 loss 0.07159
06/12/2023 00:19:27 - INFO - __main__ -   epoch 1 step 4700 loss 0.07013
06/12/2023 00:19:57 - INFO - __main__ -   ***** Running evaluation *****
06/12/2023 00:19:57 - INFO - __main__ -     Num examples = 9604
06/12/2023 00:19:57 - INFO - __main__ -     Batch size = 64
06/12/2023 00:23:10 - INFO - __main__ -     eval_loss = 0.9695
06/12/2023 00:23:10 - INFO - __main__ -     eval_mrr = 0.3422
06/12/2023 00:24:56 - INFO - __main__ -   epoch 1 step 4800 loss 0.06096
06/12/2023 00:27:14 - INFO - __main__ -   epoch 1 step 4900 loss 0.06939
06/12/2023 00:29:30 - INFO - __main__ -   epoch 1 step 5000 loss 0.06834
06/12/2023 00:31:46 - INFO - __main__ -   epoch 1 step 5100 loss 0.06712
06/12/2023 00:34:01 - INFO - __main__ -   epoch 1 step 5200 loss 0.06478
06/12/2023 00:36:17 - INFO - __main__ -   epoch 1 step 5300 loss 0.0634
06/12/2023 00:38:32 - INFO - __main__ -   epoch 1 step 5400 loss 0.06321
06/12/2023 00:40:47 - INFO - __main__ -   epoch 1 step 5500 loss 0.06162
06/12/2023 00:40:59 - INFO - __main__ -   ***** Running evaluation *****
06/12/2023 00:40:59 - INFO - __main__ -     Num examples = 9604
06/12/2023 00:40:59 - INFO - __main__ -     Batch size = 64
06/12/2023 00:44:16 - INFO - __main__ -     eval_loss = 0.9805
06/12/2023 00:44:16 - INFO - __main__ -     eval_mrr = 0.3595
06/12/2023 00:46:20 - INFO - __main__ -   epoch 1 step 5600 loss 0.04948
06/12/2023 00:48:37 - INFO - __main__ -   epoch 1 step 5700 loss 0.05026
06/12/2023 00:50:53 - INFO - __main__ -   epoch 1 step 5800 loss 0.05562
06/12/2023 00:53:08 - INFO - __main__ -   epoch 1 step 5900 loss 0.0588
06/12/2023 00:55:24 - INFO - __main__ -   epoch 1 step 6000 loss 0.0579
06/12/2023 00:57:42 - INFO - __main__ -   epoch 1 step 6100 loss 0.06159
06/12/2023 00:59:57 - INFO - __main__ -   epoch 1 step 6200 loss 0.06281
06/12/2023 01:02:07 - INFO - __main__ -   ***** Running evaluation *****
06/12/2023 01:02:07 - INFO - __main__ -     Num examples = 9604
06/12/2023 01:02:07 - INFO - __main__ -     Batch size = 64
06/12/2023 01:05:21 - INFO - __main__ -     eval_loss = 0.9407
06/12/2023 01:05:21 - INFO - __main__ -     eval_mrr = 0.3748
06/12/2023 01:05:21 - INFO - __main__ -     ********************
06/12/2023 01:05:21 - INFO - __main__ -     Best mrr:0.3748
06/12/2023 01:05:21 - INFO - __main__ -     ********************
06/12/2023 01:05:23 - INFO - __main__ -   Saving model checkpoint to /disk/scratch_big/s2334723/saved_models/python_ddp_32/checkpoint-best-mrr/model.bin
06/12/2023 01:05:28 - INFO - __main__ -   epoch 1 step 6300 loss 0.07471
06/12/2023 01:07:45 - INFO - __main__ -   epoch 1 step 6400 loss 0.06401
06/12/2023 01:10:01 - INFO - __main__ -   epoch 1 step 6500 loss 0.06081
06/12/2023 01:12:17 - INFO - __main__ -   epoch 1 step 6600 loss 0.06769
06/12/2023 01:14:32 - INFO - __main__ -   epoch 1 step 6700 loss 0.06343
06/12/2023 01:16:50 - INFO - __main__ -   epoch 1 step 6800 loss 0.06125
06/12/2023 01:19:05 - INFO - __main__ -   epoch 1 step 6900 loss 0.06355
06/12/2023 01:21:20 - INFO - __main__ -   epoch 1 step 7000 loss 0.05991
06/12/2023 01:23:13 - INFO - __main__ -   ***** Running evaluation *****
06/12/2023 01:23:13 - INFO - __main__ -     Num examples = 9604
06/12/2023 01:23:13 - INFO - __main__ -     Batch size = 64
06/12/2023 01:26:22 - INFO - __main__ -     eval_loss = 0.9021
06/12/2023 01:26:22 - INFO - __main__ -     eval_mrr = 0.3754
06/12/2023 01:26:22 - INFO - __main__ -     ********************
06/12/2023 01:26:22 - INFO - __main__ -     Best mrr:0.3754
06/12/2023 01:26:22 - INFO - __main__ -     ********************
06/12/2023 01:26:25 - INFO - __main__ -   Saving model checkpoint to /disk/scratch_big/s2334723/saved_models/python_ddp_32/checkpoint-best-mrr/model.bin
06/12/2023 01:26:47 - INFO - __main__ -   epoch 1 step 7100 loss 0.08062
06/12/2023 01:29:04 - INFO - __main__ -   epoch 1 step 7200 loss 0.05565
06/12/2023 01:31:21 - INFO - __main__ -   epoch 1 step 7300 loss 0.05375
06/12/2023 01:33:37 - INFO - __main__ -   epoch 1 step 7400 loss 0.05705
06/12/2023 01:35:52 - INFO - __main__ -   epoch 1 step 7500 loss 0.05683
06/12/2023 01:38:10 - INFO - __main__ -   epoch 1 step 7600 loss 0.06021
06/12/2023 01:40:26 - INFO - __main__ -   epoch 1 step 7700 loss 0.06012
06/12/2023 01:42:41 - INFO - __main__ -   epoch 1 step 7800 loss 0.06035
06/12/2023 01:44:15 - INFO - __main__ -   ***** Running evaluation *****
06/12/2023 01:44:15 - INFO - __main__ -     Num examples = 9604
06/12/2023 01:44:15 - INFO - __main__ -     Batch size = 64
06/12/2023 01:47:30 - INFO - __main__ -     eval_loss = 0.8997
06/12/2023 01:47:30 - INFO - __main__ -     eval_mrr = 0.3754
06/12/2023 01:47:30 - INFO - __main__ -     ********************
06/12/2023 01:47:30 - INFO - __main__ -     Best mrr:0.3754
06/12/2023 01:47:30 - INFO - __main__ -     ********************
06/12/2023 01:47:33 - INFO - __main__ -   Saving model checkpoint to /disk/scratch_big/s2334723/saved_models/python_ddp_32/checkpoint-best-mrr/model.bin
06/12/2023 01:47:33 - INFO - __main__ -   ***** Running evaluation *****
06/12/2023 01:47:33 - INFO - __main__ -     Num examples = 9604
06/12/2023 01:47:33 - INFO - __main__ -     Batch size = 64
06/12/2023 01:50:49 - INFO - __main__ -   ***** Eval results *****
06/12/2023 01:50:49 - INFO - __main__ -     eval_loss = 0.8997
06/12/2023 01:50:49 - INFO - __main__ -     eval_mrr = 0.3754
06/12/2023 01:51:19 - INFO - __main__ -   ***** Running Test *****
06/12/2023 01:51:19 - INFO - __main__ -     Num examples = 19210
06/12/2023 01:51:19 - INFO - __main__ -     Batch size = 64
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:        epoch ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████
wandb:   epoch_step ▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇▇█▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▆▇▇██
wandb:    eval_loss ▇▄█▃▂▃▂▁▁▂▃▄▄▆▁▃▃▂▂▂
wandb:     eval_mrr ▂▄▁▄▄▄▄▅▅▅▅▅▆▅▇▆▇███
wandb: example_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:     log_loss █▂▁▁▁▁▁▁▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▁▁▁▁▁▁▁▁
wandb: scheduler_lr ▂▃▅▇███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb: 
wandb: Run summary:
wandb:        epoch 1
wandb:   epoch_step 7869
wandb: example_step 503640
wandb: scheduler_lr 0.0
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2334723/codebert-search-Adv/code/wandb/offline-run-20230611_183803-9gwls0ho
wandb: Find logs at: ./wandb/offline-run-20230611_183803-9gwls0ho/logs
